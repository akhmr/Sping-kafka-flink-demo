2024-12-07 22:03:52,266 INFO o.s.b.StartupInfoLogger [main] Starting DemoApplication using Java 17.0.10 with PID 33879 (/Users/thakur/git/Sping-kafka-flink-demo/target/classes started by thakur in /Users/thakur/git/Sping-kafka-flink-demo)
2024-12-07 22:03:52,269 DEBUG o.s.b.StartupInfoLogger [main] Running with Spring Boot v3.4.1-SNAPSHOT, Spring v6.2.1-SNAPSHOT
2024-12-07 22:03:52,270 INFO o.s.b.SpringApplication [main] No active profile set, falling back to 1 default profile: "default"
2024-12-07 22:03:54,388 INFO o.s.b.w.e.t.TomcatWebServer [main] Tomcat initialized with port 8001 (http)
2024-12-07 22:03:54,405 INFO o.a.j.l.DirectJDKLog [main] Initializing ProtocolHandler ["http-nio-0.0.0.0-8001"]
2024-12-07 22:03:54,409 INFO o.a.j.l.DirectJDKLog [main] Starting service [Tomcat]
2024-12-07 22:03:54,410 INFO o.a.j.l.DirectJDKLog [main] Starting Servlet engine: [Apache Tomcat/10.1.33]
2024-12-07 22:03:54,554 INFO o.a.j.l.DirectJDKLog [main] Initializing Spring embedded WebApplicationContext
2024-12-07 22:03:54,554 INFO o.s.b.w.s.c.ServletWebServerApplicationContext [main] Root WebApplicationContext: initialization completed in 2187 ms
2024-12-07 22:03:59,698 INFO o.a.k.c.c.AbstractConfig [Thread-1] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-null-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = null
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 524288
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2024-12-07 22:03:59,751 INFO o.a.k.c.t.i.KafkaMetricsCollector$StateLedger [Thread-1] initializing Kafka metrics collector
2024-12-07 22:03:59,887 INFO o.a.j.l.DirectJDKLog [main] Starting ProtocolHandler ["http-nio-0.0.0.0-8001"]
2024-12-07 22:03:59,909 INFO o.s.b.w.e.t.TomcatWebServer [main] Tomcat started on port 8001 (http) with context path '/'
2024-12-07 22:03:59,921 INFO o.a.k.c.u.AppInfoParser$AppInfo [Thread-1] Kafka version: 3.8.1
2024-12-07 22:03:59,923 INFO o.a.k.c.u.AppInfoParser$AppInfo [Thread-1] Kafka commitId: 70d6ff42debf7e17
2024-12-07 22:03:59,923 INFO o.a.k.c.u.AppInfoParser$AppInfo [Thread-1] Kafka startTimeMs: 1733589239915
2024-12-07 22:03:59,933 INFO o.a.k.c.c.AbstractConfig [main] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-my-group-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = my-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2024-12-07 22:03:59,939 INFO o.a.k.c.t.i.KafkaMetricsCollector$StateLedger [main] initializing Kafka metrics collector
2024-12-07 22:03:59,980 INFO o.a.k.c.u.AppInfoParser$AppInfo [main] Kafka version: 3.8.1
2024-12-07 22:03:59,981 INFO o.a.k.c.u.AppInfoParser$AppInfo [main] Kafka commitId: 70d6ff42debf7e17
2024-12-07 22:03:59,981 INFO o.a.k.c.u.AppInfoParser$AppInfo [main] Kafka startTimeMs: 1733589239980
2024-12-07 22:03:59,986 INFO o.a.k.c.c.i.LegacyKafkaConsumer [main] [Consumer clientId=consumer-my-group-2, groupId=my-group] Subscribed to topic(s): evenTopic
2024-12-07 22:04:00,002 INFO o.a.k.c.c.AbstractConfig [main] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-my-group-3
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = my-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2024-12-07 22:04:00,006 INFO o.a.k.c.t.i.KafkaMetricsCollector$StateLedger [main] initializing Kafka metrics collector
2024-12-07 22:04:00,025 INFO o.a.k.c.u.AppInfoParser$AppInfo [main] Kafka version: 3.8.1
2024-12-07 22:04:00,026 INFO o.a.k.c.u.AppInfoParser$AppInfo [main] Kafka commitId: 70d6ff42debf7e17
2024-12-07 22:04:00,026 INFO o.a.k.c.u.AppInfoParser$AppInfo [main] Kafka startTimeMs: 1733589240025
2024-12-07 22:04:00,027 INFO o.a.k.c.c.i.LegacyKafkaConsumer [main] [Consumer clientId=consumer-my-group-3, groupId=my-group] Subscribed to topic(s): oddTopic
2024-12-07 22:04:00,054 INFO o.s.b.StartupInfoLogger [main] Started DemoApplication in 8.384 seconds (process running for 9.546)
2024-12-07 22:04:00,255 INFO o.a.k.c.Metadata [Thread-1] [Consumer clientId=consumer-null-1, groupId=null] Cluster ID: gI2WBDqdQ9Kcc-CZ22MWVA
2024-12-07 22:04:00,257 INFO o.a.k.c.Metadata [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-my-group-2, groupId=my-group] Cluster ID: gI2WBDqdQ9Kcc-CZ22MWVA
2024-12-07 22:04:00,257 INFO o.a.k.c.Metadata [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [Consumer clientId=consumer-my-group-3, groupId=my-group] Cluster ID: gI2WBDqdQ9Kcc-CZ22MWVA
2024-12-07 22:04:00,261 INFO o.a.k.c.c.i.AbstractCoordinator$FindCoordinatorResponseHandler [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [Consumer clientId=consumer-my-group-3, groupId=my-group] Discovered group coordinator localhost:9092 (id: 2147483647 rack: null)
2024-12-07 22:04:00,260 INFO o.a.k.c.c.i.AbstractCoordinator$FindCoordinatorResponseHandler [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-my-group-2, groupId=my-group] Discovered group coordinator localhost:9092 (id: 2147483647 rack: null)
2024-12-07 22:04:00,265 INFO o.a.k.c.c.i.AbstractCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [Consumer clientId=consumer-my-group-3, groupId=my-group] (Re-)joining group
2024-12-07 22:04:00,265 INFO o.a.k.c.c.i.AbstractCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-my-group-2, groupId=my-group] (Re-)joining group
2024-12-07 22:04:00,273 INFO o.a.k.c.m.Metrics [Thread-1] Metrics scheduler closed
2024-12-07 22:04:00,275 INFO o.a.k.c.m.Metrics [Thread-1] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2024-12-07 22:04:00,275 INFO o.a.k.c.m.Metrics [Thread-1] Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2024-12-07 22:04:00,275 INFO o.a.k.c.m.Metrics [Thread-1] Metrics reporters closed
2024-12-07 22:04:00,291 INFO o.a.k.c.u.AppInfoParser [Thread-1] App info kafka.consumer for consumer-null-1 unregistered
2024-12-07 22:04:00,291 INFO o.a.k.c.c.i.AbstractCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-my-group-2, groupId=my-group] Request joining group due to: need to re-join with the given member-id: consumer-my-group-2-4dc5e59d-36e0-494f-8746-07c82acc5e8b
2024-12-07 22:04:00,291 INFO o.a.k.c.c.i.AbstractCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-my-group-2, groupId=my-group] (Re-)joining group
2024-12-07 22:04:00,291 INFO o.a.k.c.c.i.AbstractCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [Consumer clientId=consumer-my-group-3, groupId=my-group] Request joining group due to: need to re-join with the given member-id: consumer-my-group-3-1853742d-e2de-4ca1-815e-323db920883a
2024-12-07 22:04:00,292 INFO o.a.b.s.i.k.KafkaUnboundedSource [Thread-1] Partitions assigned to split 0 (total 1): personTopic-0
2024-12-07 22:04:00,292 INFO o.a.k.c.c.i.AbstractCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [Consumer clientId=consumer-my-group-3, groupId=my-group] (Re-)joining group
2024-12-07 22:04:00,297 INFO o.a.k.c.c.i.AbstractCoordinator$JoinGroupResponseHandler [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [Consumer clientId=consumer-my-group-3, groupId=my-group] Successfully joined group with generation Generation{generationId=92, memberId='consumer-my-group-3-1853742d-e2de-4ca1-815e-323db920883a', protocol='range'}
2024-12-07 22:04:00,297 INFO o.a.k.c.c.i.AbstractCoordinator$JoinGroupResponseHandler [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-my-group-2, groupId=my-group] Successfully joined group with generation Generation{generationId=92, memberId='consumer-my-group-2-4dc5e59d-36e0-494f-8746-07c82acc5e8b', protocol='range'}
2024-12-07 22:04:00,317 INFO o.a.k.c.c.i.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [Consumer clientId=consumer-my-group-3, groupId=my-group] Finished assignment for group at generation 92: {consumer-my-group-2-4dc5e59d-36e0-494f-8746-07c82acc5e8b=Assignment(partitions=[evenTopic-0]), consumer-my-group-3-1853742d-e2de-4ca1-815e-323db920883a=Assignment(partitions=[oddTopic-0])}
2024-12-07 22:04:00,332 INFO o.a.k.c.c.i.AbstractCoordinator$SyncGroupResponseHandler [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-my-group-2, groupId=my-group] Successfully synced group in generation Generation{generationId=92, memberId='consumer-my-group-2-4dc5e59d-36e0-494f-8746-07c82acc5e8b', protocol='range'}
2024-12-07 22:04:00,332 INFO o.a.k.c.c.i.AbstractCoordinator$SyncGroupResponseHandler [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [Consumer clientId=consumer-my-group-3, groupId=my-group] Successfully synced group in generation Generation{generationId=92, memberId='consumer-my-group-3-1853742d-e2de-4ca1-815e-323db920883a', protocol='range'}
2024-12-07 22:04:00,337 INFO o.a.k.c.c.i.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [Consumer clientId=consumer-my-group-3, groupId=my-group] Notifying assignor about the new Assignment(partitions=[oddTopic-0])
2024-12-07 22:04:00,337 INFO o.a.k.c.c.i.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-my-group-2, groupId=my-group] Notifying assignor about the new Assignment(partitions=[evenTopic-0])
2024-12-07 22:04:00,344 INFO o.a.k.c.c.i.ConsumerRebalanceListenerInvoker [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-my-group-2, groupId=my-group] Adding newly assigned partitions: evenTopic-0
2024-12-07 22:04:00,345 INFO o.a.k.c.c.i.ConsumerRebalanceListenerInvoker [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [Consumer clientId=consumer-my-group-3, groupId=my-group] Adding newly assigned partitions: oddTopic-0
2024-12-07 22:04:00,366 INFO o.a.k.c.c.i.ConsumerUtils [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] Setting offset for partition oddTopic-0 to the committed offset FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 0 rack: null)], epoch=0}}
2024-12-07 22:04:00,366 INFO o.a.k.c.c.i.ConsumerUtils [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] Setting offset for partition evenTopic-0 to the committed offset FetchPosition{offset=68, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 0 rack: null)], epoch=0}}
2024-12-07 22:04:00,388 INFO o.s.c.l.LogAccessor [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] my-group: partitions assigned: [evenTopic-0]
2024-12-07 22:04:00,388 INFO o.s.c.l.LogAccessor [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] my-group: partitions assigned: [oddTopic-0]
2024-12-07 22:04:00,394 INFO o.a.k.c.c.AbstractConfig [direct-runner-worker] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-null-4
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = null
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 524288
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2024-12-07 22:04:00,401 INFO o.a.k.c.t.i.KafkaMetricsCollector$StateLedger [direct-runner-worker] initializing Kafka metrics collector
2024-12-07 22:04:00,468 INFO o.a.k.c.u.AppInfoParser$AppInfo [direct-runner-worker] Kafka version: 3.8.1
2024-12-07 22:04:00,469 INFO o.a.k.c.u.AppInfoParser$AppInfo [direct-runner-worker] Kafka commitId: 70d6ff42debf7e17
2024-12-07 22:04:00,470 INFO o.a.k.c.u.AppInfoParser$AppInfo [direct-runner-worker] Kafka startTimeMs: 1733589240467
2024-12-07 22:04:00,497 INFO o.a.k.c.c.i.LegacyKafkaConsumer [direct-runner-worker] [Consumer clientId=consumer-null-4, groupId=null] Assigned to partition(s): personTopic-0
2024-12-07 22:04:00,517 INFO o.a.k.c.Metadata [KafkaConsumerPoll-thread] [Consumer clientId=consumer-null-4, groupId=null] Cluster ID: gI2WBDqdQ9Kcc-CZ22MWVA
2024-12-07 22:04:00,543 INFO o.a.k.c.c.i.SubscriptionState [KafkaConsumerPoll-thread] [Consumer clientId=consumer-null-4, groupId=null] Resetting offset for partition personTopic-0 to position FetchPosition{offset=81, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 0 rack: null)], epoch=0}}.
2024-12-07 22:04:00,546 INFO o.a.b.s.i.k.KafkaUnboundedReader [direct-runner-worker] Reader-0: reading from personTopic-0 starting at offset 81
2024-12-07 22:04:00,573 INFO o.a.k.c.c.AbstractConfig [direct-runner-worker] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-Reader-0_offset_consumer_1851833869_none-5
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = Reader-0_offset_consumer_1851833869_none
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 524288
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2024-12-07 22:04:00,578 INFO o.a.k.c.t.i.KafkaMetricsCollector$StateLedger [direct-runner-worker] initializing Kafka metrics collector
2024-12-07 22:04:00,652 INFO o.a.k.c.u.AppInfoParser$AppInfo [direct-runner-worker] Kafka version: 3.8.1
2024-12-07 22:04:00,654 INFO o.a.k.c.u.AppInfoParser$AppInfo [direct-runner-worker] Kafka commitId: 70d6ff42debf7e17
2024-12-07 22:04:00,654 INFO o.a.k.c.u.AppInfoParser$AppInfo [direct-runner-worker] Kafka startTimeMs: 1733589240652
2024-12-07 22:04:00,689 INFO o.a.k.c.Metadata [direct-runner-worker] [Consumer clientId=consumer-Reader-0_offset_consumer_1851833869_none-5, groupId=Reader-0_offset_consumer_1851833869_none] Cluster ID: gI2WBDqdQ9Kcc-CZ22MWVA
2024-12-07 22:04:41,772 INFO o.a.j.l.DirectJDKLog [http-nio-0.0.0.0-8001-exec-3] Initializing Spring DispatcherServlet 'dispatcherServlet'
2024-12-07 22:04:41,777 INFO o.s.w.s.FrameworkServlet [http-nio-0.0.0.0-8001-exec-3] Initializing Servlet 'dispatcherServlet'
2024-12-07 22:04:41,809 INFO o.s.w.s.FrameworkServlet [http-nio-0.0.0.0-8001-exec-3] Completed initialization in 31 ms
2024-12-07 22:04:42,078 INFO c.a.c.DataController [http-nio-0.0.0.0-8001-exec-3] Person Person [name=pooja, address=hamirpur, dateOfBirth=20/12/1986] 
2024-12-07 22:04:42,156 INFO o.a.k.c.c.AbstractConfig [http-nio-0.0.0.0-8001-exec-3] ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = assignment-producer-1
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = none
	compression.zstd.level = 3
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2024-12-07 22:04:42,162 INFO o.a.k.c.t.i.KafkaMetricsCollector$StateLedger [http-nio-0.0.0.0-8001-exec-3] initializing Kafka metrics collector
2024-12-07 22:04:42,188 INFO o.a.k.c.p.KafkaProducer [http-nio-0.0.0.0-8001-exec-3] [Producer clientId=assignment-producer-1] Instantiated an idempotent producer.
2024-12-07 22:04:42,256 INFO o.a.k.c.u.AppInfoParser$AppInfo [http-nio-0.0.0.0-8001-exec-3] Kafka version: 3.8.1
2024-12-07 22:04:42,259 INFO o.a.k.c.u.AppInfoParser$AppInfo [http-nio-0.0.0.0-8001-exec-3] Kafka commitId: 70d6ff42debf7e17
2024-12-07 22:04:42,260 INFO o.a.k.c.u.AppInfoParser$AppInfo [http-nio-0.0.0.0-8001-exec-3] Kafka startTimeMs: 1733589282254
2024-12-07 22:04:42,307 INFO o.a.k.c.Metadata [kafka-producer-network-thread | assignment-producer-1] [Producer clientId=assignment-producer-1] Cluster ID: gI2WBDqdQ9Kcc-CZ22MWVA
2024-12-07 22:04:42,311 INFO o.a.k.c.p.i.TransactionManager [kafka-producer-network-thread | assignment-producer-1] [Producer clientId=assignment-producer-1] ProducerId set to 3027 with epoch 0
2024-12-07 22:04:42,499 INFO o.a.b.s.i.k.KafkaUnboundedReader [direct-runner-worker] Reader-0: first record offset 81
2024-12-07 22:04:43,107 INFO o.a.k.c.c.AbstractConfig [direct-runner-worker] ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-1
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = none
	compression.zstd.level = 3
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 3
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2024-12-07 22:04:43,112 INFO o.a.k.c.t.i.KafkaMetricsCollector$StateLedger [direct-runner-worker] initializing Kafka metrics collector
2024-12-07 22:04:43,116 INFO o.a.k.c.p.KafkaProducer [direct-runner-worker] [Producer clientId=producer-1] Instantiated an idempotent producer.
2024-12-07 22:04:43,121 INFO o.a.k.c.u.AppInfoParser$AppInfo [direct-runner-worker] Kafka version: 3.8.1
2024-12-07 22:04:43,122 INFO o.a.k.c.u.AppInfoParser$AppInfo [direct-runner-worker] Kafka commitId: 70d6ff42debf7e17
2024-12-07 22:04:43,122 INFO o.a.k.c.u.AppInfoParser$AppInfo [direct-runner-worker] Kafka startTimeMs: 1733589283121
2024-12-07 22:04:43,136 INFO o.a.k.c.Metadata [kafka-producer-network-thread | producer-1] [Producer clientId=producer-1] Cluster ID: gI2WBDqdQ9Kcc-CZ22MWVA
2024-12-07 22:04:43,140 INFO o.a.k.c.p.i.TransactionManager [kafka-producer-network-thread | producer-1] [Producer clientId=producer-1] ProducerId set to 3028 with epoch 0
2024-12-07 22:04:50,100 INFO o.a.k.c.c.i.ConsumerRebalanceListenerInvoker [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [Consumer clientId=consumer-my-group-3, groupId=my-group] Revoke previously assigned partitions oddTopic-0
2024-12-07 22:04:50,100 INFO o.a.k.c.c.i.ConsumerRebalanceListenerInvoker [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-my-group-2, groupId=my-group] Revoke previously assigned partitions evenTopic-0
2024-12-07 22:04:50,116 INFO o.s.c.l.LogAccessor [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] my-group: partitions revoked: [evenTopic-0]
2024-12-07 22:04:50,116 INFO o.s.c.l.LogAccessor [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] my-group: partitions revoked: [oddTopic-0]
2024-12-07 22:04:50,121 INFO o.a.k.c.c.i.AbstractCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [Consumer clientId=consumer-my-group-3, groupId=my-group] Member consumer-my-group-3-1853742d-e2de-4ca1-815e-323db920883a sending LeaveGroup request to coordinator localhost:9092 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
2024-12-07 22:04:50,121 INFO o.a.k.c.c.i.AbstractCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-my-group-2, groupId=my-group] Member consumer-my-group-2-4dc5e59d-36e0-494f-8746-07c82acc5e8b sending LeaveGroup request to coordinator localhost:9092 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
2024-12-07 22:04:50,122 INFO o.a.k.c.c.i.AbstractCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [Consumer clientId=consumer-my-group-3, groupId=my-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2024-12-07 22:04:50,122 INFO o.a.k.c.c.i.AbstractCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-my-group-2, groupId=my-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2024-12-07 22:04:50,122 INFO o.a.k.c.c.i.AbstractCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [Consumer clientId=consumer-my-group-3, groupId=my-group] Request joining group due to: consumer pro-actively leaving the group
2024-12-07 22:04:50,123 INFO o.a.k.c.c.i.LegacyKafkaConsumer [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [Consumer clientId=consumer-my-group-3, groupId=my-group] Unsubscribed all topics or patterns and assigned partitions
2024-12-07 22:04:50,123 INFO o.a.k.c.c.i.AbstractCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-my-group-2, groupId=my-group] Request joining group due to: consumer pro-actively leaving the group
2024-12-07 22:04:50,123 INFO o.a.k.c.c.i.LegacyKafkaConsumer [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-my-group-2, groupId=my-group] Unsubscribed all topics or patterns and assigned partitions
2024-12-07 22:04:50,130 INFO o.a.k.c.c.i.AbstractCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-my-group-2, groupId=my-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2024-12-07 22:04:50,130 INFO o.a.k.c.c.i.AbstractCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [Consumer clientId=consumer-my-group-3, groupId=my-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2024-12-07 22:04:50,130 INFO o.a.k.c.c.i.AbstractCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-my-group-2, groupId=my-group] Request joining group due to: consumer pro-actively leaving the group
2024-12-07 22:04:50,130 INFO o.a.k.c.c.i.AbstractCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [Consumer clientId=consumer-my-group-3, groupId=my-group] Request joining group due to: consumer pro-actively leaving the group
2024-12-07 22:04:50,257 INFO o.a.k.c.m.Metrics [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] Metrics scheduler closed
2024-12-07 22:04:50,257 INFO o.a.k.c.m.Metrics [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] Metrics scheduler closed
2024-12-07 22:04:50,264 INFO o.a.k.c.m.Metrics [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2024-12-07 22:04:50,264 INFO o.a.k.c.m.Metrics [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2024-12-07 22:04:50,265 INFO o.a.k.c.m.Metrics [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2024-12-07 22:04:50,266 INFO o.a.k.c.m.Metrics [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2024-12-07 22:04:50,268 INFO o.a.k.c.m.Metrics [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] Metrics reporters closed
2024-12-07 22:04:50,268 INFO o.a.k.c.m.Metrics [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] Metrics reporters closed
2024-12-07 22:04:50,284 INFO o.a.k.c.u.AppInfoParser [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] App info kafka.consumer for consumer-my-group-3 unregistered
2024-12-07 22:04:50,291 INFO o.s.c.l.LogAccessor [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] my-group: Consumer stopped
2024-12-07 22:04:50,298 INFO o.a.k.c.u.AppInfoParser [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] App info kafka.consumer for consumer-my-group-2 unregistered
2024-12-07 22:04:50,299 INFO o.s.c.l.LogAccessor [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] my-group: Consumer stopped
2024-12-07 22:04:50,302 INFO o.s.b.w.e.t.GracefulShutdown [SpringApplicationShutdownHook] Commencing graceful shutdown. Waiting for active requests to complete
2024-12-07 22:04:50,336 INFO o.s.b.w.e.t.GracefulShutdown [tomcat-shutdown] Graceful shutdown complete
2024-12-07 22:04:50,353 INFO o.a.k.c.p.KafkaProducer [SpringApplicationShutdownHook] [Producer clientId=assignment-producer-1] Closing the Kafka producer with timeoutMillis = 30000 ms.
2024-12-07 22:04:50,397 INFO o.a.k.c.m.Metrics [SpringApplicationShutdownHook] Metrics scheduler closed
2024-12-07 22:04:50,400 INFO o.a.k.c.m.Metrics [SpringApplicationShutdownHook] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2024-12-07 22:04:50,400 INFO o.a.k.c.m.Metrics [SpringApplicationShutdownHook] Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2024-12-07 22:04:50,400 INFO o.a.k.c.m.Metrics [SpringApplicationShutdownHook] Metrics reporters closed
2024-12-07 22:04:50,407 INFO o.a.k.c.u.AppInfoParser [SpringApplicationShutdownHook] App info kafka.producer for assignment-producer-1 unregistered
2024-12-07 22:07:01,605 INFO o.s.b.StartupInfoLogger [main] Starting DemoApplication using Java 17.0.10 with PID 34132 (/Users/thakur/git/Sping-kafka-flink-demo/target/classes started by thakur in /Users/thakur/git/Sping-kafka-flink-demo)
2024-12-07 22:07:01,608 DEBUG o.s.b.StartupInfoLogger [main] Running with Spring Boot v3.4.1-SNAPSHOT, Spring v6.2.1-SNAPSHOT
2024-12-07 22:07:01,610 INFO o.s.b.SpringApplication [main] No active profile set, falling back to 1 default profile: "default"
2024-12-07 22:07:03,743 INFO o.s.b.w.e.t.TomcatWebServer [main] Tomcat initialized with port 8001 (http)
2024-12-07 22:07:03,757 INFO o.a.j.l.DirectJDKLog [main] Initializing ProtocolHandler ["http-nio-0.0.0.0-8001"]
2024-12-07 22:07:03,761 INFO o.a.j.l.DirectJDKLog [main] Starting service [Tomcat]
2024-12-07 22:07:03,761 INFO o.a.j.l.DirectJDKLog [main] Starting Servlet engine: [Apache Tomcat/10.1.33]
2024-12-07 22:07:03,892 INFO o.a.j.l.DirectJDKLog [main] Initializing Spring embedded WebApplicationContext
2024-12-07 22:07:03,894 INFO o.s.b.w.s.c.ServletWebServerApplicationContext [main] Root WebApplicationContext: initialization completed in 2205 ms
2024-12-07 22:07:08,382 INFO o.a.j.l.DirectJDKLog [main] Starting ProtocolHandler ["http-nio-0.0.0.0-8001"]
2024-12-07 22:07:08,400 INFO o.a.k.c.c.AbstractConfig [Thread-1] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-null-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = null
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 524288
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2024-12-07 22:07:08,418 INFO o.s.b.w.e.t.TomcatWebServer [main] Tomcat started on port 8001 (http) with context path '/'
2024-12-07 22:07:08,442 INFO o.a.k.c.c.AbstractConfig [main] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-my-group-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = my-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2024-12-07 22:07:08,447 INFO o.a.k.c.t.i.KafkaMetricsCollector$StateLedger [Thread-1] initializing Kafka metrics collector
2024-12-07 22:07:08,451 INFO o.a.k.c.t.i.KafkaMetricsCollector$StateLedger [main] initializing Kafka metrics collector
2024-12-07 22:07:08,613 INFO o.a.k.c.u.AppInfoParser$AppInfo [Thread-1] Kafka version: 3.8.1
2024-12-07 22:07:08,616 INFO o.a.k.c.u.AppInfoParser$AppInfo [Thread-1] Kafka commitId: 70d6ff42debf7e17
2024-12-07 22:07:08,618 INFO o.a.k.c.u.AppInfoParser$AppInfo [Thread-1] Kafka startTimeMs: 1733589428606
2024-12-07 22:07:08,625 INFO o.a.k.c.u.AppInfoParser$AppInfo [main] Kafka version: 3.8.1
2024-12-07 22:07:08,626 INFO o.a.k.c.u.AppInfoParser$AppInfo [main] Kafka commitId: 70d6ff42debf7e17
2024-12-07 22:07:08,626 INFO o.a.k.c.u.AppInfoParser$AppInfo [main] Kafka startTimeMs: 1733589428625
2024-12-07 22:07:08,632 INFO o.a.k.c.c.i.LegacyKafkaConsumer [main] [Consumer clientId=consumer-my-group-2, groupId=my-group] Subscribed to topic(s): evenTopic
2024-12-07 22:07:08,649 INFO o.a.k.c.c.AbstractConfig [main] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-my-group-3
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = my-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2024-12-07 22:07:08,652 INFO o.a.k.c.t.i.KafkaMetricsCollector$StateLedger [main] initializing Kafka metrics collector
2024-12-07 22:07:08,680 INFO o.a.k.c.u.AppInfoParser$AppInfo [main] Kafka version: 3.8.1
2024-12-07 22:07:08,681 INFO o.a.k.c.u.AppInfoParser$AppInfo [main] Kafka commitId: 70d6ff42debf7e17
2024-12-07 22:07:08,682 INFO o.a.k.c.u.AppInfoParser$AppInfo [main] Kafka startTimeMs: 1733589428679
2024-12-07 22:07:08,685 INFO o.a.k.c.c.i.LegacyKafkaConsumer [main] [Consumer clientId=consumer-my-group-3, groupId=my-group] Subscribed to topic(s): oddTopic
2024-12-07 22:07:08,704 INFO o.s.b.StartupInfoLogger [main] Started DemoApplication in 7.89 seconds (process running for 9.271)
2024-12-07 22:07:08,934 INFO o.a.k.c.Metadata [Thread-1] [Consumer clientId=consumer-null-1, groupId=null] Cluster ID: gI2WBDqdQ9Kcc-CZ22MWVA
2024-12-07 22:07:08,936 INFO o.a.k.c.Metadata [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-my-group-2, groupId=my-group] Cluster ID: gI2WBDqdQ9Kcc-CZ22MWVA
2024-12-07 22:07:08,936 INFO o.a.k.c.Metadata [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [Consumer clientId=consumer-my-group-3, groupId=my-group] Cluster ID: gI2WBDqdQ9Kcc-CZ22MWVA
2024-12-07 22:07:08,939 INFO o.a.k.c.c.i.AbstractCoordinator$FindCoordinatorResponseHandler [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-my-group-2, groupId=my-group] Discovered group coordinator localhost:9092 (id: 2147483647 rack: null)
2024-12-07 22:07:08,939 INFO o.a.k.c.c.i.AbstractCoordinator$FindCoordinatorResponseHandler [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [Consumer clientId=consumer-my-group-3, groupId=my-group] Discovered group coordinator localhost:9092 (id: 2147483647 rack: null)
2024-12-07 22:07:08,943 INFO o.a.k.c.c.i.AbstractCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-my-group-2, groupId=my-group] (Re-)joining group
2024-12-07 22:07:08,943 INFO o.a.k.c.c.i.AbstractCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [Consumer clientId=consumer-my-group-3, groupId=my-group] (Re-)joining group
2024-12-07 22:07:08,950 INFO o.a.k.c.m.Metrics [Thread-1] Metrics scheduler closed
2024-12-07 22:07:08,950 INFO o.a.k.c.m.Metrics [Thread-1] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2024-12-07 22:07:08,951 INFO o.a.k.c.m.Metrics [Thread-1] Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2024-12-07 22:07:08,951 INFO o.a.k.c.m.Metrics [Thread-1] Metrics reporters closed
2024-12-07 22:07:08,963 INFO o.a.k.c.u.AppInfoParser [Thread-1] App info kafka.consumer for consumer-null-1 unregistered
2024-12-07 22:07:08,965 INFO o.a.b.s.i.k.KafkaUnboundedSource [Thread-1] Partitions assigned to split 0 (total 1): personTopic-0
2024-12-07 22:07:08,965 INFO o.a.k.c.c.i.AbstractCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-my-group-2, groupId=my-group] Request joining group due to: need to re-join with the given member-id: consumer-my-group-2-71afe2ae-6571-4ab1-8b94-aa0d9f097e66
2024-12-07 22:07:08,965 INFO o.a.k.c.c.i.AbstractCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [Consumer clientId=consumer-my-group-3, groupId=my-group] Request joining group due to: need to re-join with the given member-id: consumer-my-group-3-9d87f02d-0b11-443e-b95b-87a0d47e0ed4
2024-12-07 22:07:08,965 INFO o.a.k.c.c.i.AbstractCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-my-group-2, groupId=my-group] (Re-)joining group
2024-12-07 22:07:08,966 INFO o.a.k.c.c.i.AbstractCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [Consumer clientId=consumer-my-group-3, groupId=my-group] (Re-)joining group
2024-12-07 22:07:08,970 INFO o.a.k.c.c.i.AbstractCoordinator$JoinGroupResponseHandler [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [Consumer clientId=consumer-my-group-3, groupId=my-group] Successfully joined group with generation Generation{generationId=96, memberId='consumer-my-group-3-9d87f02d-0b11-443e-b95b-87a0d47e0ed4', protocol='range'}
2024-12-07 22:07:08,970 INFO o.a.k.c.c.i.AbstractCoordinator$JoinGroupResponseHandler [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-my-group-2, groupId=my-group] Successfully joined group with generation Generation{generationId=96, memberId='consumer-my-group-2-71afe2ae-6571-4ab1-8b94-aa0d9f097e66', protocol='range'}
2024-12-07 22:07:08,989 INFO o.a.k.c.c.i.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-my-group-2, groupId=my-group] Finished assignment for group at generation 96: {consumer-my-group-3-9d87f02d-0b11-443e-b95b-87a0d47e0ed4=Assignment(partitions=[oddTopic-0]), consumer-my-group-2-71afe2ae-6571-4ab1-8b94-aa0d9f097e66=Assignment(partitions=[evenTopic-0])}
2024-12-07 22:07:09,012 INFO o.a.k.c.c.i.AbstractCoordinator$SyncGroupResponseHandler [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [Consumer clientId=consumer-my-group-3, groupId=my-group] Successfully synced group in generation Generation{generationId=96, memberId='consumer-my-group-3-9d87f02d-0b11-443e-b95b-87a0d47e0ed4', protocol='range'}
2024-12-07 22:07:09,012 INFO o.a.k.c.c.i.AbstractCoordinator$SyncGroupResponseHandler [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-my-group-2, groupId=my-group] Successfully synced group in generation Generation{generationId=96, memberId='consumer-my-group-2-71afe2ae-6571-4ab1-8b94-aa0d9f097e66', protocol='range'}
2024-12-07 22:07:09,016 INFO o.a.k.c.c.i.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [Consumer clientId=consumer-my-group-3, groupId=my-group] Notifying assignor about the new Assignment(partitions=[oddTopic-0])
2024-12-07 22:07:09,016 INFO o.a.k.c.c.i.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-my-group-2, groupId=my-group] Notifying assignor about the new Assignment(partitions=[evenTopic-0])
2024-12-07 22:07:09,020 INFO o.a.k.c.c.i.ConsumerRebalanceListenerInvoker [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [Consumer clientId=consumer-my-group-3, groupId=my-group] Adding newly assigned partitions: oddTopic-0
2024-12-07 22:07:09,020 INFO o.a.k.c.c.i.ConsumerRebalanceListenerInvoker [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-my-group-2, groupId=my-group] Adding newly assigned partitions: evenTopic-0
2024-12-07 22:07:09,071 INFO o.a.k.c.c.i.ConsumerUtils [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] Setting offset for partition evenTopic-0 to the committed offset FetchPosition{offset=68, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 0 rack: null)], epoch=0}}
2024-12-07 22:07:09,071 INFO o.a.k.c.c.i.ConsumerUtils [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] Setting offset for partition oddTopic-0 to the committed offset FetchPosition{offset=36, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 0 rack: null)], epoch=0}}
2024-12-07 22:07:09,104 INFO o.s.c.l.LogAccessor [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] my-group: partitions assigned: [evenTopic-0]
2024-12-07 22:07:09,119 INFO o.a.k.c.c.AbstractConfig [direct-runner-worker] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-null-4
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = null
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 524288
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2024-12-07 22:07:09,129 INFO o.a.k.c.t.i.KafkaMetricsCollector$StateLedger [direct-runner-worker] initializing Kafka metrics collector
2024-12-07 22:07:09,185 INFO o.a.k.c.u.AppInfoParser$AppInfo [direct-runner-worker] Kafka version: 3.8.1
2024-12-07 22:07:09,186 INFO o.a.k.c.u.AppInfoParser$AppInfo [direct-runner-worker] Kafka commitId: 70d6ff42debf7e17
2024-12-07 22:07:09,186 INFO o.a.k.c.u.AppInfoParser$AppInfo [direct-runner-worker] Kafka startTimeMs: 1733589429184
2024-12-07 22:07:09,201 INFO o.s.c.l.LogAccessor [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] my-group: partitions assigned: [oddTopic-0]
2024-12-07 22:07:09,217 INFO o.a.k.c.c.i.LegacyKafkaConsumer [direct-runner-worker] [Consumer clientId=consumer-null-4, groupId=null] Assigned to partition(s): personTopic-0
2024-12-07 22:07:09,239 INFO o.a.k.c.Metadata [KafkaConsumerPoll-thread] [Consumer clientId=consumer-null-4, groupId=null] Cluster ID: gI2WBDqdQ9Kcc-CZ22MWVA
2024-12-07 22:07:09,254 INFO o.a.k.c.c.i.SubscriptionState [KafkaConsumerPoll-thread] [Consumer clientId=consumer-null-4, groupId=null] Resetting offset for partition personTopic-0 to position FetchPosition{offset=83, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 0 rack: null)], epoch=0}}.
2024-12-07 22:07:09,256 INFO o.a.b.s.i.k.KafkaUnboundedReader [direct-runner-worker] Reader-0: reading from personTopic-0 starting at offset 83
2024-12-07 22:07:09,261 INFO o.a.k.c.c.AbstractConfig [direct-runner-worker] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-Reader-0_offset_consumer_588831253_none-5
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = Reader-0_offset_consumer_588831253_none
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 524288
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2024-12-07 22:07:09,265 INFO o.a.k.c.t.i.KafkaMetricsCollector$StateLedger [direct-runner-worker] initializing Kafka metrics collector
2024-12-07 22:07:09,344 INFO o.a.k.c.u.AppInfoParser$AppInfo [direct-runner-worker] Kafka version: 3.8.1
2024-12-07 22:07:09,344 INFO o.a.k.c.u.AppInfoParser$AppInfo [direct-runner-worker] Kafka commitId: 70d6ff42debf7e17
2024-12-07 22:07:09,344 INFO o.a.k.c.u.AppInfoParser$AppInfo [direct-runner-worker] Kafka startTimeMs: 1733589429343
2024-12-07 22:07:09,371 INFO o.a.k.c.Metadata [direct-runner-worker] [Consumer clientId=consumer-Reader-0_offset_consumer_588831253_none-5, groupId=Reader-0_offset_consumer_588831253_none] Cluster ID: gI2WBDqdQ9Kcc-CZ22MWVA
2024-12-07 22:10:20,973 INFO o.a.k.c.c.i.ConsumerRebalanceListenerInvoker [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-my-group-2, groupId=my-group] Revoke previously assigned partitions evenTopic-0
2024-12-07 22:10:20,973 INFO o.a.k.c.c.i.ConsumerRebalanceListenerInvoker [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [Consumer clientId=consumer-my-group-3, groupId=my-group] Revoke previously assigned partitions oddTopic-0
2024-12-07 22:10:20,987 INFO o.s.c.l.LogAccessor [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] my-group: partitions revoked: [evenTopic-0]
2024-12-07 22:10:20,987 INFO o.s.c.l.LogAccessor [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] my-group: partitions revoked: [oddTopic-0]
2024-12-07 22:10:20,993 INFO o.a.k.c.c.i.AbstractCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [Consumer clientId=consumer-my-group-3, groupId=my-group] Member consumer-my-group-3-9d87f02d-0b11-443e-b95b-87a0d47e0ed4 sending LeaveGroup request to coordinator localhost:9092 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
2024-12-07 22:10:20,993 INFO o.a.k.c.c.i.AbstractCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-my-group-2, groupId=my-group] Member consumer-my-group-2-71afe2ae-6571-4ab1-8b94-aa0d9f097e66 sending LeaveGroup request to coordinator localhost:9092 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
2024-12-07 22:10:20,998 INFO o.a.k.c.c.i.AbstractCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [Consumer clientId=consumer-my-group-3, groupId=my-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2024-12-07 22:10:20,998 INFO o.a.k.c.c.i.AbstractCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-my-group-2, groupId=my-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2024-12-07 22:10:21,000 INFO o.a.k.c.c.i.AbstractCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-my-group-2, groupId=my-group] Request joining group due to: consumer pro-actively leaving the group
2024-12-07 22:10:21,000 INFO o.a.k.c.c.i.AbstractCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [Consumer clientId=consumer-my-group-3, groupId=my-group] Request joining group due to: consumer pro-actively leaving the group
2024-12-07 22:10:21,000 INFO o.a.k.c.c.i.LegacyKafkaConsumer [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-my-group-2, groupId=my-group] Unsubscribed all topics or patterns and assigned partitions
2024-12-07 22:10:21,001 INFO o.a.k.c.c.i.LegacyKafkaConsumer [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [Consumer clientId=consumer-my-group-3, groupId=my-group] Unsubscribed all topics or patterns and assigned partitions
2024-12-07 22:10:21,014 INFO o.a.k.c.c.i.AbstractCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [Consumer clientId=consumer-my-group-3, groupId=my-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2024-12-07 22:10:21,014 INFO o.a.k.c.c.i.AbstractCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-my-group-2, groupId=my-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2024-12-07 22:10:21,025 INFO o.a.k.c.c.i.AbstractCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [Consumer clientId=consumer-my-group-3, groupId=my-group] Request joining group due to: consumer pro-actively leaving the group
2024-12-07 22:10:21,025 INFO o.a.k.c.c.i.AbstractCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-my-group-2, groupId=my-group] Request joining group due to: consumer pro-actively leaving the group
2024-12-07 22:10:21,431 INFO o.a.k.c.m.Metrics [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] Metrics scheduler closed
2024-12-07 22:10:21,431 INFO o.a.k.c.m.Metrics [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] Metrics scheduler closed
2024-12-07 22:10:21,434 INFO o.a.k.c.m.Metrics [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2024-12-07 22:10:21,434 INFO o.a.k.c.m.Metrics [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2024-12-07 22:10:21,435 INFO o.a.k.c.m.Metrics [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2024-12-07 22:10:21,435 INFO o.a.k.c.m.Metrics [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2024-12-07 22:10:21,435 INFO o.a.k.c.m.Metrics [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] Metrics reporters closed
2024-12-07 22:10:21,435 INFO o.a.k.c.m.Metrics [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] Metrics reporters closed
2024-12-07 22:10:21,470 INFO o.a.k.c.u.AppInfoParser [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] App info kafka.consumer for consumer-my-group-3 unregistered
2024-12-07 22:10:21,473 INFO o.a.k.c.u.AppInfoParser [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] App info kafka.consumer for consumer-my-group-2 unregistered
2024-12-07 22:10:21,476 INFO o.s.c.l.LogAccessor [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] my-group: Consumer stopped
2024-12-07 22:10:21,476 INFO o.s.c.l.LogAccessor [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] my-group: Consumer stopped
2024-12-07 22:10:21,484 INFO o.s.b.w.e.t.GracefulShutdown [SpringApplicationShutdownHook] Commencing graceful shutdown. Waiting for active requests to complete
2024-12-07 22:10:21,531 INFO o.s.b.w.e.t.GracefulShutdown [tomcat-shutdown] Graceful shutdown complete
2024-12-07 22:10:30,927 INFO o.s.b.StartupInfoLogger [main] Starting DemoApplication using Java 17.0.10 with PID 34325 (/Users/thakur/git/Sping-kafka-flink-demo/target/classes started by thakur in /Users/thakur/git/Sping-kafka-flink-demo)
2024-12-07 22:10:30,929 DEBUG o.s.b.StartupInfoLogger [main] Running with Spring Boot v3.4.1-SNAPSHOT, Spring v6.2.1-SNAPSHOT
2024-12-07 22:10:30,931 INFO o.s.b.SpringApplication [main] No active profile set, falling back to 1 default profile: "default"
2024-12-07 22:10:33,053 INFO o.s.b.w.e.t.TomcatWebServer [main] Tomcat initialized with port 8001 (http)
2024-12-07 22:10:33,067 INFO o.a.j.l.DirectJDKLog [main] Initializing ProtocolHandler ["http-nio-0.0.0.0-8001"]
2024-12-07 22:10:33,070 INFO o.a.j.l.DirectJDKLog [main] Starting service [Tomcat]
2024-12-07 22:10:33,070 INFO o.a.j.l.DirectJDKLog [main] Starting Servlet engine: [Apache Tomcat/10.1.33]
2024-12-07 22:10:33,214 INFO o.a.j.l.DirectJDKLog [main] Initializing Spring embedded WebApplicationContext
2024-12-07 22:10:33,215 INFO o.s.b.w.s.c.ServletWebServerApplicationContext [main] Root WebApplicationContext: initialization completed in 2210 ms
2024-12-07 22:10:37,461 INFO o.a.j.l.DirectJDKLog [main] Starting ProtocolHandler ["http-nio-0.0.0.0-8001"]
2024-12-07 22:10:37,492 INFO o.s.b.w.e.t.TomcatWebServer [main] Tomcat started on port 8001 (http) with context path '/'
2024-12-07 22:10:37,501 INFO o.a.k.c.c.AbstractConfig [Thread-1] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-null-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = null
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 524288
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2024-12-07 22:10:37,513 INFO o.a.k.c.c.AbstractConfig [main] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-my-group-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = my-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2024-12-07 22:10:37,544 INFO o.a.k.c.t.i.KafkaMetricsCollector$StateLedger [Thread-1] initializing Kafka metrics collector
2024-12-07 22:10:37,547 INFO o.a.k.c.t.i.KafkaMetricsCollector$StateLedger [main] initializing Kafka metrics collector
2024-12-07 22:10:37,700 INFO o.a.k.c.u.AppInfoParser$AppInfo [Thread-1] Kafka version: 3.8.1
2024-12-07 22:10:37,703 INFO o.a.k.c.u.AppInfoParser$AppInfo [Thread-1] Kafka commitId: 70d6ff42debf7e17
2024-12-07 22:10:37,704 INFO o.a.k.c.u.AppInfoParser$AppInfo [Thread-1] Kafka startTimeMs: 1733589637694
2024-12-07 22:10:37,710 INFO o.a.k.c.u.AppInfoParser$AppInfo [main] Kafka version: 3.8.1
2024-12-07 22:10:37,710 INFO o.a.k.c.u.AppInfoParser$AppInfo [main] Kafka commitId: 70d6ff42debf7e17
2024-12-07 22:10:37,710 INFO o.a.k.c.u.AppInfoParser$AppInfo [main] Kafka startTimeMs: 1733589637709
2024-12-07 22:10:37,713 INFO o.a.k.c.c.i.LegacyKafkaConsumer [main] [Consumer clientId=consumer-my-group-2, groupId=my-group] Subscribed to topic(s): evenTopic
2024-12-07 22:10:37,729 INFO o.a.k.c.c.AbstractConfig [main] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-my-group-3
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = my-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2024-12-07 22:10:37,731 INFO o.a.k.c.t.i.KafkaMetricsCollector$StateLedger [main] initializing Kafka metrics collector
2024-12-07 22:10:37,752 INFO o.a.k.c.u.AppInfoParser$AppInfo [main] Kafka version: 3.8.1
2024-12-07 22:10:37,752 INFO o.a.k.c.u.AppInfoParser$AppInfo [main] Kafka commitId: 70d6ff42debf7e17
2024-12-07 22:10:37,752 INFO o.a.k.c.u.AppInfoParser$AppInfo [main] Kafka startTimeMs: 1733589637752
2024-12-07 22:10:37,756 INFO o.a.k.c.c.i.LegacyKafkaConsumer [main] [Consumer clientId=consumer-my-group-3, groupId=my-group] Subscribed to topic(s): oddTopic
2024-12-07 22:10:37,782 INFO o.s.b.StartupInfoLogger [main] Started DemoApplication in 7.535 seconds (process running for 8.755)
2024-12-07 22:10:38,012 INFO o.a.k.c.Metadata [Thread-1] [Consumer clientId=consumer-null-1, groupId=null] Cluster ID: gI2WBDqdQ9Kcc-CZ22MWVA
2024-12-07 22:10:38,013 INFO o.a.k.c.Metadata [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-my-group-2, groupId=my-group] Cluster ID: gI2WBDqdQ9Kcc-CZ22MWVA
2024-12-07 22:10:38,013 INFO o.a.k.c.Metadata [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [Consumer clientId=consumer-my-group-3, groupId=my-group] Cluster ID: gI2WBDqdQ9Kcc-CZ22MWVA
2024-12-07 22:10:38,015 INFO o.a.k.c.c.i.AbstractCoordinator$FindCoordinatorResponseHandler [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [Consumer clientId=consumer-my-group-3, groupId=my-group] Discovered group coordinator localhost:9092 (id: 2147483647 rack: null)
2024-12-07 22:10:38,015 INFO o.a.k.c.c.i.AbstractCoordinator$FindCoordinatorResponseHandler [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-my-group-2, groupId=my-group] Discovered group coordinator localhost:9092 (id: 2147483647 rack: null)
2024-12-07 22:10:38,021 INFO o.a.k.c.c.i.AbstractCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-my-group-2, groupId=my-group] (Re-)joining group
2024-12-07 22:10:38,021 INFO o.a.k.c.c.i.AbstractCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [Consumer clientId=consumer-my-group-3, groupId=my-group] (Re-)joining group
2024-12-07 22:10:38,027 INFO o.a.k.c.m.Metrics [Thread-1] Metrics scheduler closed
2024-12-07 22:10:38,027 INFO o.a.k.c.m.Metrics [Thread-1] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2024-12-07 22:10:38,027 INFO o.a.k.c.m.Metrics [Thread-1] Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2024-12-07 22:10:38,027 INFO o.a.k.c.m.Metrics [Thread-1] Metrics reporters closed
2024-12-07 22:10:38,039 INFO o.a.k.c.u.AppInfoParser [Thread-1] App info kafka.consumer for consumer-null-1 unregistered
2024-12-07 22:10:38,040 INFO o.a.b.s.i.k.KafkaUnboundedSource [Thread-1] Partitions assigned to split 0 (total 1): personTopic-0
2024-12-07 22:10:38,041 INFO o.a.k.c.c.i.AbstractCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-my-group-2, groupId=my-group] Request joining group due to: need to re-join with the given member-id: consumer-my-group-2-bc970f9c-5c09-4e2a-b0ba-43f176e910ea
2024-12-07 22:10:38,041 INFO o.a.k.c.c.i.AbstractCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [Consumer clientId=consumer-my-group-3, groupId=my-group] Request joining group due to: need to re-join with the given member-id: consumer-my-group-3-2b586396-2c7d-4534-8d20-658e55346bf6
2024-12-07 22:10:38,041 INFO o.a.k.c.c.i.AbstractCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-my-group-2, groupId=my-group] (Re-)joining group
2024-12-07 22:10:38,042 INFO o.a.k.c.c.i.AbstractCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [Consumer clientId=consumer-my-group-3, groupId=my-group] (Re-)joining group
2024-12-07 22:10:38,046 INFO o.a.k.c.c.i.AbstractCoordinator$JoinGroupResponseHandler [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [Consumer clientId=consumer-my-group-3, groupId=my-group] Successfully joined group with generation Generation{generationId=98, memberId='consumer-my-group-3-2b586396-2c7d-4534-8d20-658e55346bf6', protocol='range'}
2024-12-07 22:10:38,046 INFO o.a.k.c.c.i.AbstractCoordinator$JoinGroupResponseHandler [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-my-group-2, groupId=my-group] Successfully joined group with generation Generation{generationId=98, memberId='consumer-my-group-2-bc970f9c-5c09-4e2a-b0ba-43f176e910ea', protocol='range'}
2024-12-07 22:10:38,062 INFO o.a.k.c.c.i.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [Consumer clientId=consumer-my-group-3, groupId=my-group] Finished assignment for group at generation 98: {consumer-my-group-3-2b586396-2c7d-4534-8d20-658e55346bf6=Assignment(partitions=[oddTopic-0]), consumer-my-group-2-bc970f9c-5c09-4e2a-b0ba-43f176e910ea=Assignment(partitions=[evenTopic-0])}
2024-12-07 22:10:38,073 INFO o.a.k.c.c.i.AbstractCoordinator$SyncGroupResponseHandler [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [Consumer clientId=consumer-my-group-3, groupId=my-group] Successfully synced group in generation Generation{generationId=98, memberId='consumer-my-group-3-2b586396-2c7d-4534-8d20-658e55346bf6', protocol='range'}
2024-12-07 22:10:38,073 INFO o.a.k.c.c.i.AbstractCoordinator$SyncGroupResponseHandler [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-my-group-2, groupId=my-group] Successfully synced group in generation Generation{generationId=98, memberId='consumer-my-group-2-bc970f9c-5c09-4e2a-b0ba-43f176e910ea', protocol='range'}
2024-12-07 22:10:38,077 INFO o.a.k.c.c.i.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-my-group-2, groupId=my-group] Notifying assignor about the new Assignment(partitions=[evenTopic-0])
2024-12-07 22:10:38,077 INFO o.a.k.c.c.i.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [Consumer clientId=consumer-my-group-3, groupId=my-group] Notifying assignor about the new Assignment(partitions=[oddTopic-0])
2024-12-07 22:10:38,080 INFO o.a.k.c.c.i.ConsumerRebalanceListenerInvoker [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [Consumer clientId=consumer-my-group-3, groupId=my-group] Adding newly assigned partitions: oddTopic-0
2024-12-07 22:10:38,080 INFO o.a.k.c.c.i.ConsumerRebalanceListenerInvoker [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-my-group-2, groupId=my-group] Adding newly assigned partitions: evenTopic-0
2024-12-07 22:10:38,103 INFO o.a.k.c.c.i.ConsumerUtils [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] Setting offset for partition evenTopic-0 to the committed offset FetchPosition{offset=68, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 0 rack: null)], epoch=0}}
2024-12-07 22:10:38,103 INFO o.a.k.c.c.i.ConsumerUtils [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] Setting offset for partition oddTopic-0 to the committed offset FetchPosition{offset=36, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 0 rack: null)], epoch=0}}
2024-12-07 22:10:38,122 INFO o.s.c.l.LogAccessor [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] my-group: partitions assigned: [evenTopic-0]
2024-12-07 22:10:38,122 INFO o.s.c.l.LogAccessor [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] my-group: partitions assigned: [oddTopic-0]
2024-12-07 22:10:38,127 INFO o.a.k.c.c.AbstractConfig [direct-runner-worker] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-null-4
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = null
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 524288
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2024-12-07 22:10:38,133 INFO o.a.k.c.t.i.KafkaMetricsCollector$StateLedger [direct-runner-worker] initializing Kafka metrics collector
2024-12-07 22:10:38,187 INFO o.a.k.c.u.AppInfoParser$AppInfo [direct-runner-worker] Kafka version: 3.8.1
2024-12-07 22:10:38,188 INFO o.a.k.c.u.AppInfoParser$AppInfo [direct-runner-worker] Kafka commitId: 70d6ff42debf7e17
2024-12-07 22:10:38,188 INFO o.a.k.c.u.AppInfoParser$AppInfo [direct-runner-worker] Kafka startTimeMs: 1733589638187
2024-12-07 22:10:38,208 INFO o.a.k.c.c.i.LegacyKafkaConsumer [direct-runner-worker] [Consumer clientId=consumer-null-4, groupId=null] Assigned to partition(s): personTopic-0
2024-12-07 22:10:38,229 INFO o.a.k.c.Metadata [KafkaConsumerPoll-thread] [Consumer clientId=consumer-null-4, groupId=null] Cluster ID: gI2WBDqdQ9Kcc-CZ22MWVA
2024-12-07 22:10:38,237 INFO o.a.k.c.c.i.SubscriptionState [KafkaConsumerPoll-thread] [Consumer clientId=consumer-null-4, groupId=null] Resetting offset for partition personTopic-0 to position FetchPosition{offset=83, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 0 rack: null)], epoch=0}}.
2024-12-07 22:10:38,239 INFO o.a.b.s.i.k.KafkaUnboundedReader [direct-runner-worker] Reader-0: reading from personTopic-0 starting at offset 83
2024-12-07 22:10:38,243 INFO o.a.k.c.c.AbstractConfig [direct-runner-worker] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-Reader-0_offset_consumer_1940863924_none-5
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = Reader-0_offset_consumer_1940863924_none
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 524288
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2024-12-07 22:10:38,244 INFO o.a.k.c.t.i.KafkaMetricsCollector$StateLedger [direct-runner-worker] initializing Kafka metrics collector
2024-12-07 22:10:38,285 INFO o.a.k.c.u.AppInfoParser$AppInfo [direct-runner-worker] Kafka version: 3.8.1
2024-12-07 22:10:38,285 INFO o.a.k.c.u.AppInfoParser$AppInfo [direct-runner-worker] Kafka commitId: 70d6ff42debf7e17
2024-12-07 22:10:38,285 INFO o.a.k.c.u.AppInfoParser$AppInfo [direct-runner-worker] Kafka startTimeMs: 1733589638285
2024-12-07 22:10:38,303 INFO o.a.k.c.Metadata [direct-runner-worker] [Consumer clientId=consumer-Reader-0_offset_consumer_1940863924_none-5, groupId=Reader-0_offset_consumer_1940863924_none] Cluster ID: gI2WBDqdQ9Kcc-CZ22MWVA
2024-12-07 22:11:11,987 INFO o.a.k.c.c.i.ConsumerRebalanceListenerInvoker [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [Consumer clientId=consumer-my-group-3, groupId=my-group] Revoke previously assigned partitions oddTopic-0
2024-12-07 22:11:11,987 INFO o.a.k.c.c.i.ConsumerRebalanceListenerInvoker [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-my-group-2, groupId=my-group] Revoke previously assigned partitions evenTopic-0
2024-12-07 22:11:12,000 INFO o.s.c.l.LogAccessor [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] my-group: partitions revoked: [evenTopic-0]
2024-12-07 22:11:12,000 INFO o.s.c.l.LogAccessor [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] my-group: partitions revoked: [oddTopic-0]
2024-12-07 22:11:12,006 INFO o.a.k.c.c.i.AbstractCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [Consumer clientId=consumer-my-group-3, groupId=my-group] Member consumer-my-group-3-2b586396-2c7d-4534-8d20-658e55346bf6 sending LeaveGroup request to coordinator localhost:9092 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
2024-12-07 22:11:12,006 INFO o.a.k.c.c.i.AbstractCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-my-group-2, groupId=my-group] Member consumer-my-group-2-bc970f9c-5c09-4e2a-b0ba-43f176e910ea sending LeaveGroup request to coordinator localhost:9092 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
2024-12-07 22:11:12,009 INFO o.a.k.c.c.i.AbstractCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [Consumer clientId=consumer-my-group-3, groupId=my-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2024-12-07 22:11:12,009 INFO o.a.k.c.c.i.AbstractCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-my-group-2, groupId=my-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2024-12-07 22:11:12,009 INFO o.a.k.c.c.i.AbstractCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [Consumer clientId=consumer-my-group-3, groupId=my-group] Request joining group due to: consumer pro-actively leaving the group
2024-12-07 22:11:12,009 INFO o.a.k.c.c.i.AbstractCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-my-group-2, groupId=my-group] Request joining group due to: consumer pro-actively leaving the group
2024-12-07 22:11:12,009 INFO o.a.k.c.c.i.LegacyKafkaConsumer [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [Consumer clientId=consumer-my-group-3, groupId=my-group] Unsubscribed all topics or patterns and assigned partitions
2024-12-07 22:11:12,009 INFO o.a.k.c.c.i.LegacyKafkaConsumer [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-my-group-2, groupId=my-group] Unsubscribed all topics or patterns and assigned partitions
2024-12-07 22:11:12,015 INFO o.a.k.c.c.i.AbstractCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [Consumer clientId=consumer-my-group-3, groupId=my-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2024-12-07 22:11:12,015 INFO o.a.k.c.c.i.AbstractCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-my-group-2, groupId=my-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2024-12-07 22:11:12,016 INFO o.a.k.c.c.i.AbstractCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [Consumer clientId=consumer-my-group-3, groupId=my-group] Request joining group due to: consumer pro-actively leaving the group
2024-12-07 22:11:12,016 INFO o.a.k.c.c.i.AbstractCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-my-group-2, groupId=my-group] Request joining group due to: consumer pro-actively leaving the group
2024-12-07 22:11:12,298 INFO o.a.k.c.m.Metrics [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] Metrics scheduler closed
2024-12-07 22:11:12,298 INFO o.a.k.c.m.Metrics [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] Metrics scheduler closed
2024-12-07 22:11:12,300 INFO o.a.k.c.m.Metrics [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2024-12-07 22:11:12,301 INFO o.a.k.c.m.Metrics [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2024-12-07 22:11:12,300 INFO o.a.k.c.m.Metrics [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2024-12-07 22:11:12,302 INFO o.a.k.c.m.Metrics [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] Metrics reporters closed
2024-12-07 22:11:12,302 INFO o.a.k.c.m.Metrics [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2024-12-07 22:11:12,304 INFO o.a.k.c.m.Metrics [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] Metrics reporters closed
2024-12-07 22:11:12,332 INFO o.a.k.c.u.AppInfoParser [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] App info kafka.consumer for consumer-my-group-2 unregistered
2024-12-07 22:11:12,333 INFO o.a.k.c.u.AppInfoParser [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] App info kafka.consumer for consumer-my-group-3 unregistered
2024-12-07 22:11:12,339 INFO o.s.c.l.LogAccessor [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] my-group: Consumer stopped
2024-12-07 22:11:12,339 INFO o.s.c.l.LogAccessor [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] my-group: Consumer stopped
2024-12-07 22:11:12,348 INFO o.s.b.w.e.t.GracefulShutdown [SpringApplicationShutdownHook] Commencing graceful shutdown. Waiting for active requests to complete
2024-12-07 22:11:12,372 INFO o.s.b.w.e.t.GracefulShutdown [tomcat-shutdown] Graceful shutdown complete
2024-12-07 22:11:26,307 INFO o.s.b.StartupInfoLogger [main] Starting DemoApplication using Java 17.0.10 with PID 34346 (/Users/thakur/git/Sping-kafka-flink-demo/target/classes started by thakur in /Users/thakur/git/Sping-kafka-flink-demo)
2024-12-07 22:11:26,310 DEBUG o.s.b.StartupInfoLogger [main] Running with Spring Boot v3.4.1-SNAPSHOT, Spring v6.2.1-SNAPSHOT
2024-12-07 22:11:26,312 INFO o.s.b.SpringApplication [main] No active profile set, falling back to 1 default profile: "default"
2024-12-07 22:11:28,569 INFO o.s.b.w.e.t.TomcatWebServer [main] Tomcat initialized with port 8001 (http)
2024-12-07 22:11:28,589 INFO o.a.j.l.DirectJDKLog [main] Initializing ProtocolHandler ["http-nio-0.0.0.0-8001"]
2024-12-07 22:11:28,591 INFO o.a.j.l.DirectJDKLog [main] Starting service [Tomcat]
2024-12-07 22:11:28,592 INFO o.a.j.l.DirectJDKLog [main] Starting Servlet engine: [Apache Tomcat/10.1.33]
2024-12-07 22:11:28,730 INFO o.a.j.l.DirectJDKLog [main] Initializing Spring embedded WebApplicationContext
2024-12-07 22:11:28,734 INFO o.s.b.w.s.c.ServletWebServerApplicationContext [main] Root WebApplicationContext: initialization completed in 2350 ms
2024-12-07 22:11:32,774 INFO o.a.k.c.c.AbstractConfig [Thread-1] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-null-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = null
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 524288
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2024-12-07 22:11:32,819 INFO o.a.j.l.DirectJDKLog [main] Starting ProtocolHandler ["http-nio-0.0.0.0-8001"]
2024-12-07 22:11:32,823 INFO o.a.k.c.t.i.KafkaMetricsCollector$StateLedger [Thread-1] initializing Kafka metrics collector
2024-12-07 22:11:32,846 INFO o.s.b.w.e.t.TomcatWebServer [main] Tomcat started on port 8001 (http) with context path '/'
2024-12-07 22:11:32,872 INFO o.a.k.c.c.AbstractConfig [main] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-my-group-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = my-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2024-12-07 22:11:32,901 INFO o.a.k.c.t.i.KafkaMetricsCollector$StateLedger [main] initializing Kafka metrics collector
2024-12-07 22:11:32,975 INFO o.a.k.c.u.AppInfoParser$AppInfo [Thread-1] Kafka version: 3.8.1
2024-12-07 22:11:32,980 INFO o.a.k.c.u.AppInfoParser$AppInfo [Thread-1] Kafka commitId: 70d6ff42debf7e17
2024-12-07 22:11:32,980 INFO o.a.k.c.u.AppInfoParser$AppInfo [Thread-1] Kafka startTimeMs: 1733589692969
2024-12-07 22:11:32,986 INFO o.a.k.c.u.AppInfoParser$AppInfo [main] Kafka version: 3.8.1
2024-12-07 22:11:32,987 INFO o.a.k.c.u.AppInfoParser$AppInfo [main] Kafka commitId: 70d6ff42debf7e17
2024-12-07 22:11:32,987 INFO o.a.k.c.u.AppInfoParser$AppInfo [main] Kafka startTimeMs: 1733589692986
2024-12-07 22:11:32,992 INFO o.a.k.c.c.i.LegacyKafkaConsumer [main] [Consumer clientId=consumer-my-group-2, groupId=my-group] Subscribed to topic(s): evenTopic
2024-12-07 22:11:33,003 INFO o.a.k.c.c.AbstractConfig [main] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-my-group-3
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = my-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2024-12-07 22:11:33,005 INFO o.a.k.c.t.i.KafkaMetricsCollector$StateLedger [main] initializing Kafka metrics collector
2024-12-07 22:11:33,023 INFO o.a.k.c.u.AppInfoParser$AppInfo [main] Kafka version: 3.8.1
2024-12-07 22:11:33,024 INFO o.a.k.c.u.AppInfoParser$AppInfo [main] Kafka commitId: 70d6ff42debf7e17
2024-12-07 22:11:33,024 INFO o.a.k.c.u.AppInfoParser$AppInfo [main] Kafka startTimeMs: 1733589693023
2024-12-07 22:11:33,025 INFO o.a.k.c.c.i.LegacyKafkaConsumer [main] [Consumer clientId=consumer-my-group-3, groupId=my-group] Subscribed to topic(s): oddTopic
2024-12-07 22:11:33,046 INFO o.s.b.StartupInfoLogger [main] Started DemoApplication in 7.435 seconds (process running for 8.6)
2024-12-07 22:11:33,273 INFO o.a.k.c.Metadata [Thread-1] [Consumer clientId=consumer-null-1, groupId=null] Cluster ID: gI2WBDqdQ9Kcc-CZ22MWVA
2024-12-07 22:11:33,277 INFO o.a.k.c.Metadata [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-my-group-2, groupId=my-group] Cluster ID: gI2WBDqdQ9Kcc-CZ22MWVA
2024-12-07 22:11:33,277 INFO o.a.k.c.Metadata [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [Consumer clientId=consumer-my-group-3, groupId=my-group] Cluster ID: gI2WBDqdQ9Kcc-CZ22MWVA
2024-12-07 22:11:33,286 INFO o.a.k.c.c.i.AbstractCoordinator$FindCoordinatorResponseHandler [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-my-group-2, groupId=my-group] Discovered group coordinator localhost:9092 (id: 2147483647 rack: null)
2024-12-07 22:11:33,286 INFO o.a.k.c.c.i.AbstractCoordinator$FindCoordinatorResponseHandler [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [Consumer clientId=consumer-my-group-3, groupId=my-group] Discovered group coordinator localhost:9092 (id: 2147483647 rack: null)
2024-12-07 22:11:33,291 INFO o.a.k.c.c.i.AbstractCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [Consumer clientId=consumer-my-group-3, groupId=my-group] (Re-)joining group
2024-12-07 22:11:33,291 INFO o.a.k.c.c.i.AbstractCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-my-group-2, groupId=my-group] (Re-)joining group
2024-12-07 22:11:33,299 INFO o.a.k.c.m.Metrics [Thread-1] Metrics scheduler closed
2024-12-07 22:11:33,300 INFO o.a.k.c.m.Metrics [Thread-1] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2024-12-07 22:11:33,300 INFO o.a.k.c.m.Metrics [Thread-1] Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2024-12-07 22:11:33,300 INFO o.a.k.c.m.Metrics [Thread-1] Metrics reporters closed
2024-12-07 22:11:33,319 INFO o.a.k.c.u.AppInfoParser [Thread-1] App info kafka.consumer for consumer-null-1 unregistered
2024-12-07 22:11:33,321 INFO o.a.b.s.i.k.KafkaUnboundedSource [Thread-1] Partitions assigned to split 0 (total 1): personTopic-0
2024-12-07 22:11:33,326 INFO o.a.k.c.c.i.AbstractCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-my-group-2, groupId=my-group] Request joining group due to: need to re-join with the given member-id: consumer-my-group-2-66318063-43cd-45b5-a6dd-d340ecde8bc4
2024-12-07 22:11:33,326 INFO o.a.k.c.c.i.AbstractCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [Consumer clientId=consumer-my-group-3, groupId=my-group] Request joining group due to: need to re-join with the given member-id: consumer-my-group-3-e842d40f-ef39-4f77-b93e-dc138590c08b
2024-12-07 22:11:33,327 INFO o.a.k.c.c.i.AbstractCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [Consumer clientId=consumer-my-group-3, groupId=my-group] (Re-)joining group
2024-12-07 22:11:33,327 INFO o.a.k.c.c.i.AbstractCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-my-group-2, groupId=my-group] (Re-)joining group
2024-12-07 22:11:33,336 INFO o.a.k.c.c.i.AbstractCoordinator$JoinGroupResponseHandler [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-my-group-2, groupId=my-group] Successfully joined group with generation Generation{generationId=100, memberId='consumer-my-group-2-66318063-43cd-45b5-a6dd-d340ecde8bc4', protocol='range'}
2024-12-07 22:11:33,336 INFO o.a.k.c.c.i.AbstractCoordinator$JoinGroupResponseHandler [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [Consumer clientId=consumer-my-group-3, groupId=my-group] Successfully joined group with generation Generation{generationId=100, memberId='consumer-my-group-3-e842d40f-ef39-4f77-b93e-dc138590c08b', protocol='range'}
2024-12-07 22:11:33,368 INFO o.a.k.c.c.i.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [Consumer clientId=consumer-my-group-3, groupId=my-group] Finished assignment for group at generation 100: {consumer-my-group-3-e842d40f-ef39-4f77-b93e-dc138590c08b=Assignment(partitions=[oddTopic-0]), consumer-my-group-2-66318063-43cd-45b5-a6dd-d340ecde8bc4=Assignment(partitions=[evenTopic-0])}
2024-12-07 22:11:33,384 INFO o.a.k.c.c.i.AbstractCoordinator$SyncGroupResponseHandler [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [Consumer clientId=consumer-my-group-3, groupId=my-group] Successfully synced group in generation Generation{generationId=100, memberId='consumer-my-group-3-e842d40f-ef39-4f77-b93e-dc138590c08b', protocol='range'}
2024-12-07 22:11:33,384 INFO o.a.k.c.c.i.AbstractCoordinator$SyncGroupResponseHandler [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-my-group-2, groupId=my-group] Successfully synced group in generation Generation{generationId=100, memberId='consumer-my-group-2-66318063-43cd-45b5-a6dd-d340ecde8bc4', protocol='range'}
2024-12-07 22:11:33,390 INFO o.a.k.c.c.i.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-my-group-2, groupId=my-group] Notifying assignor about the new Assignment(partitions=[evenTopic-0])
2024-12-07 22:11:33,391 INFO o.a.k.c.c.i.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [Consumer clientId=consumer-my-group-3, groupId=my-group] Notifying assignor about the new Assignment(partitions=[oddTopic-0])
2024-12-07 22:11:33,394 INFO o.a.k.c.c.i.ConsumerRebalanceListenerInvoker [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-my-group-2, groupId=my-group] Adding newly assigned partitions: evenTopic-0
2024-12-07 22:11:33,394 INFO o.a.k.c.c.i.ConsumerRebalanceListenerInvoker [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [Consumer clientId=consumer-my-group-3, groupId=my-group] Adding newly assigned partitions: oddTopic-0
2024-12-07 22:11:33,410 INFO o.a.k.c.c.AbstractConfig [direct-runner-worker] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-null-4
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = null
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 524288
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2024-12-07 22:11:33,411 INFO o.a.k.c.t.i.KafkaMetricsCollector$StateLedger [direct-runner-worker] initializing Kafka metrics collector
2024-12-07 22:11:33,416 INFO o.a.k.c.c.i.ConsumerUtils [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] Setting offset for partition evenTopic-0 to the committed offset FetchPosition{offset=68, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 0 rack: null)], epoch=0}}
2024-12-07 22:11:33,416 INFO o.a.k.c.c.i.ConsumerUtils [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] Setting offset for partition oddTopic-0 to the committed offset FetchPosition{offset=36, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 0 rack: null)], epoch=0}}
2024-12-07 22:11:33,437 INFO o.s.c.l.LogAccessor [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] my-group: partitions assigned: [oddTopic-0]
2024-12-07 22:11:33,437 INFO o.s.c.l.LogAccessor [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] my-group: partitions assigned: [evenTopic-0]
2024-12-07 22:11:33,469 INFO o.a.k.c.u.AppInfoParser$AppInfo [direct-runner-worker] Kafka version: 3.8.1
2024-12-07 22:11:33,470 INFO o.a.k.c.u.AppInfoParser$AppInfo [direct-runner-worker] Kafka commitId: 70d6ff42debf7e17
2024-12-07 22:11:33,470 INFO o.a.k.c.u.AppInfoParser$AppInfo [direct-runner-worker] Kafka startTimeMs: 1733589693469
2024-12-07 22:11:33,497 INFO o.a.k.c.c.i.LegacyKafkaConsumer [direct-runner-worker] [Consumer clientId=consumer-null-4, groupId=null] Assigned to partition(s): personTopic-0
2024-12-07 22:11:33,511 INFO o.a.k.c.Metadata [KafkaConsumerPoll-thread] [Consumer clientId=consumer-null-4, groupId=null] Cluster ID: gI2WBDqdQ9Kcc-CZ22MWVA
2024-12-07 22:11:33,523 INFO o.a.k.c.c.i.SubscriptionState [KafkaConsumerPoll-thread] [Consumer clientId=consumer-null-4, groupId=null] Resetting offset for partition personTopic-0 to position FetchPosition{offset=83, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 0 rack: null)], epoch=0}}.
2024-12-07 22:11:33,525 INFO o.a.b.s.i.k.KafkaUnboundedReader [direct-runner-worker] Reader-0: reading from personTopic-0 starting at offset 83
2024-12-07 22:11:33,529 INFO o.a.k.c.c.AbstractConfig [direct-runner-worker] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-Reader-0_offset_consumer_910497739_none-5
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = Reader-0_offset_consumer_910497739_none
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 524288
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2024-12-07 22:11:33,534 INFO o.a.k.c.t.i.KafkaMetricsCollector$StateLedger [direct-runner-worker] initializing Kafka metrics collector
2024-12-07 22:11:33,590 INFO o.a.k.c.u.AppInfoParser$AppInfo [direct-runner-worker] Kafka version: 3.8.1
2024-12-07 22:11:33,591 INFO o.a.k.c.u.AppInfoParser$AppInfo [direct-runner-worker] Kafka commitId: 70d6ff42debf7e17
2024-12-07 22:11:33,591 INFO o.a.k.c.u.AppInfoParser$AppInfo [direct-runner-worker] Kafka startTimeMs: 1733589693590
2024-12-07 22:11:33,644 INFO o.a.k.c.Metadata [direct-runner-worker] [Consumer clientId=consumer-Reader-0_offset_consumer_910497739_none-5, groupId=Reader-0_offset_consumer_910497739_none] Cluster ID: gI2WBDqdQ9Kcc-CZ22MWVA
2024-12-07 22:12:12,620 INFO o.a.k.c.c.i.ConsumerRebalanceListenerInvoker [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-my-group-2, groupId=my-group] Revoke previously assigned partitions evenTopic-0
2024-12-07 22:12:12,619 INFO o.a.k.c.c.i.ConsumerRebalanceListenerInvoker [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [Consumer clientId=consumer-my-group-3, groupId=my-group] Revoke previously assigned partitions oddTopic-0
2024-12-07 22:12:12,639 INFO o.s.c.l.LogAccessor [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] my-group: partitions revoked: [oddTopic-0]
2024-12-07 22:12:12,639 INFO o.s.c.l.LogAccessor [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] my-group: partitions revoked: [evenTopic-0]
2024-12-07 22:12:12,645 INFO o.a.k.c.c.i.AbstractCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-my-group-2, groupId=my-group] Member consumer-my-group-2-66318063-43cd-45b5-a6dd-d340ecde8bc4 sending LeaveGroup request to coordinator localhost:9092 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
2024-12-07 22:12:12,645 INFO o.a.k.c.c.i.AbstractCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [Consumer clientId=consumer-my-group-3, groupId=my-group] Member consumer-my-group-3-e842d40f-ef39-4f77-b93e-dc138590c08b sending LeaveGroup request to coordinator localhost:9092 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
2024-12-07 22:12:12,650 INFO o.a.k.c.c.i.AbstractCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [Consumer clientId=consumer-my-group-3, groupId=my-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2024-12-07 22:12:12,650 INFO o.a.k.c.c.i.AbstractCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-my-group-2, groupId=my-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2024-12-07 22:12:12,652 INFO o.a.k.c.c.i.AbstractCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [Consumer clientId=consumer-my-group-3, groupId=my-group] Request joining group due to: consumer pro-actively leaving the group
2024-12-07 22:12:12,652 INFO o.a.k.c.c.i.AbstractCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-my-group-2, groupId=my-group] Request joining group due to: consumer pro-actively leaving the group
2024-12-07 22:12:12,652 INFO o.a.k.c.c.i.LegacyKafkaConsumer [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [Consumer clientId=consumer-my-group-3, groupId=my-group] Unsubscribed all topics or patterns and assigned partitions
2024-12-07 22:12:12,652 INFO o.a.k.c.c.i.LegacyKafkaConsumer [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-my-group-2, groupId=my-group] Unsubscribed all topics or patterns and assigned partitions
2024-12-07 22:12:12,658 INFO o.a.k.c.c.i.AbstractCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-my-group-2, groupId=my-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2024-12-07 22:12:12,658 INFO o.a.k.c.c.i.AbstractCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [Consumer clientId=consumer-my-group-3, groupId=my-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2024-12-07 22:12:12,658 INFO o.a.k.c.c.i.AbstractCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-my-group-2, groupId=my-group] Request joining group due to: consumer pro-actively leaving the group
2024-12-07 22:12:12,658 INFO o.a.k.c.c.i.AbstractCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [Consumer clientId=consumer-my-group-3, groupId=my-group] Request joining group due to: consumer pro-actively leaving the group
2024-12-07 22:12:13,076 INFO o.a.k.c.m.Metrics [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] Metrics scheduler closed
2024-12-07 22:12:13,076 INFO o.a.k.c.m.Metrics [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] Metrics scheduler closed
2024-12-07 22:12:13,079 INFO o.a.k.c.m.Metrics [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2024-12-07 22:12:13,079 INFO o.a.k.c.m.Metrics [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2024-12-07 22:12:13,079 INFO o.a.k.c.m.Metrics [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2024-12-07 22:12:13,079 INFO o.a.k.c.m.Metrics [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2024-12-07 22:12:13,080 INFO o.a.k.c.m.Metrics [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] Metrics reporters closed
2024-12-07 22:12:13,080 INFO o.a.k.c.m.Metrics [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] Metrics reporters closed
2024-12-07 22:12:13,104 INFO o.a.k.c.u.AppInfoParser [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] App info kafka.consumer for consumer-my-group-3 unregistered
2024-12-07 22:12:13,105 INFO o.a.k.c.u.AppInfoParser [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] App info kafka.consumer for consumer-my-group-2 unregistered
2024-12-07 22:12:13,111 INFO o.s.c.l.LogAccessor [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] my-group: Consumer stopped
2024-12-07 22:12:13,111 INFO o.s.c.l.LogAccessor [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] my-group: Consumer stopped
2024-12-07 22:12:13,121 INFO o.s.b.w.e.t.GracefulShutdown [SpringApplicationShutdownHook] Commencing graceful shutdown. Waiting for active requests to complete
2024-12-07 22:12:13,165 INFO o.s.b.w.e.t.GracefulShutdown [tomcat-shutdown] Graceful shutdown complete
2024-12-07 22:12:19,607 INFO o.s.b.StartupInfoLogger [main] Starting DemoApplication using Java 17.0.10 with PID 34370 (/Users/thakur/git/Sping-kafka-flink-demo/target/classes started by thakur in /Users/thakur/git/Sping-kafka-flink-demo)
2024-12-07 22:12:19,610 DEBUG o.s.b.StartupInfoLogger [main] Running with Spring Boot v3.4.1-SNAPSHOT, Spring v6.2.1-SNAPSHOT
2024-12-07 22:12:19,611 INFO o.s.b.SpringApplication [main] No active profile set, falling back to 1 default profile: "default"
2024-12-07 22:12:21,611 INFO o.s.b.w.e.t.TomcatWebServer [main] Tomcat initialized with port 8001 (http)
2024-12-07 22:12:21,626 INFO o.a.j.l.DirectJDKLog [main] Initializing ProtocolHandler ["http-nio-0.0.0.0-8001"]
2024-12-07 22:12:21,629 INFO o.a.j.l.DirectJDKLog [main] Starting service [Tomcat]
2024-12-07 22:12:21,629 INFO o.a.j.l.DirectJDKLog [main] Starting Servlet engine: [Apache Tomcat/10.1.33]
2024-12-07 22:12:21,774 INFO o.a.j.l.DirectJDKLog [main] Initializing Spring embedded WebApplicationContext
2024-12-07 22:12:21,775 INFO o.s.b.w.s.c.ServletWebServerApplicationContext [main] Root WebApplicationContext: initialization completed in 2100 ms
2024-12-07 22:12:26,024 INFO o.a.k.c.c.AbstractConfig [Thread-1] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-null-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = null
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 524288
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2024-12-07 22:12:26,073 INFO o.a.k.c.t.i.KafkaMetricsCollector$StateLedger [Thread-1] initializing Kafka metrics collector
2024-12-07 22:12:26,342 INFO o.a.k.c.u.AppInfoParser$AppInfo [Thread-1] Kafka version: 3.8.1
2024-12-07 22:12:26,345 INFO o.a.k.c.u.AppInfoParser$AppInfo [Thread-1] Kafka commitId: 70d6ff42debf7e17
2024-12-07 22:12:26,345 INFO o.a.k.c.u.AppInfoParser$AppInfo [Thread-1] Kafka startTimeMs: 1733589746333
2024-12-07 22:12:26,433 INFO o.a.j.l.DirectJDKLog [main] Starting ProtocolHandler ["http-nio-0.0.0.0-8001"]
2024-12-07 22:12:26,454 INFO o.s.b.w.e.t.TomcatWebServer [main] Tomcat started on port 8001 (http) with context path '/'
2024-12-07 22:12:26,475 INFO o.a.k.c.c.AbstractConfig [main] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-my-group-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = my-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2024-12-07 22:12:26,480 INFO o.a.k.c.t.i.KafkaMetricsCollector$StateLedger [main] initializing Kafka metrics collector
2024-12-07 22:12:26,527 INFO o.a.k.c.u.AppInfoParser$AppInfo [main] Kafka version: 3.8.1
2024-12-07 22:12:26,528 INFO o.a.k.c.u.AppInfoParser$AppInfo [main] Kafka commitId: 70d6ff42debf7e17
2024-12-07 22:12:26,528 INFO o.a.k.c.u.AppInfoParser$AppInfo [main] Kafka startTimeMs: 1733589746527
2024-12-07 22:12:26,533 INFO o.a.k.c.c.i.LegacyKafkaConsumer [main] [Consumer clientId=consumer-my-group-2, groupId=my-group] Subscribed to topic(s): evenTopic
2024-12-07 22:12:26,558 INFO o.a.k.c.c.AbstractConfig [main] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-my-group-3
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = my-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2024-12-07 22:12:26,562 INFO o.a.k.c.t.i.KafkaMetricsCollector$StateLedger [main] initializing Kafka metrics collector
2024-12-07 22:12:26,599 INFO o.a.k.c.u.AppInfoParser$AppInfo [main] Kafka version: 3.8.1
2024-12-07 22:12:26,601 INFO o.a.k.c.u.AppInfoParser$AppInfo [main] Kafka commitId: 70d6ff42debf7e17
2024-12-07 22:12:26,601 INFO o.a.k.c.u.AppInfoParser$AppInfo [main] Kafka startTimeMs: 1733589746599
2024-12-07 22:12:26,603 INFO o.a.k.c.c.i.LegacyKafkaConsumer [main] [Consumer clientId=consumer-my-group-3, groupId=my-group] Subscribed to topic(s): oddTopic
2024-12-07 22:12:26,682 INFO o.s.b.StartupInfoLogger [main] Started DemoApplication in 7.752 seconds (process running for 8.871)
2024-12-07 22:12:26,726 INFO o.a.k.c.Metadata [Thread-1] [Consumer clientId=consumer-null-1, groupId=null] Cluster ID: gI2WBDqdQ9Kcc-CZ22MWVA
2024-12-07 22:12:26,731 INFO o.a.k.c.Metadata [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [Consumer clientId=consumer-my-group-3, groupId=my-group] Cluster ID: gI2WBDqdQ9Kcc-CZ22MWVA
2024-12-07 22:12:26,732 INFO o.a.k.c.Metadata [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-my-group-2, groupId=my-group] Cluster ID: gI2WBDqdQ9Kcc-CZ22MWVA
2024-12-07 22:12:26,734 INFO o.a.k.c.c.i.AbstractCoordinator$FindCoordinatorResponseHandler [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [Consumer clientId=consumer-my-group-3, groupId=my-group] Discovered group coordinator localhost:9092 (id: 2147483647 rack: null)
2024-12-07 22:12:26,735 INFO o.a.k.c.c.i.AbstractCoordinator$FindCoordinatorResponseHandler [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-my-group-2, groupId=my-group] Discovered group coordinator localhost:9092 (id: 2147483647 rack: null)
2024-12-07 22:12:26,745 INFO o.a.k.c.c.i.AbstractCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-my-group-2, groupId=my-group] (Re-)joining group
2024-12-07 22:12:26,745 INFO o.a.k.c.c.i.AbstractCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [Consumer clientId=consumer-my-group-3, groupId=my-group] (Re-)joining group
2024-12-07 22:12:26,776 INFO o.a.k.c.m.Metrics [Thread-1] Metrics scheduler closed
2024-12-07 22:12:26,778 INFO o.a.k.c.m.Metrics [Thread-1] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2024-12-07 22:12:26,778 INFO o.a.k.c.m.Metrics [Thread-1] Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2024-12-07 22:12:26,778 INFO o.a.k.c.m.Metrics [Thread-1] Metrics reporters closed
2024-12-07 22:12:26,791 INFO o.a.k.c.c.i.AbstractCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-my-group-2, groupId=my-group] Request joining group due to: need to re-join with the given member-id: consumer-my-group-2-9e7e5095-7a8c-492e-822d-d7ef9b8567be
2024-12-07 22:12:26,791 INFO o.a.k.c.c.i.AbstractCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [Consumer clientId=consumer-my-group-3, groupId=my-group] Request joining group due to: need to re-join with the given member-id: consumer-my-group-3-e57c731e-4b41-48a7-8e5f-70cb8fec3522
2024-12-07 22:12:26,794 INFO o.a.k.c.c.i.AbstractCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [Consumer clientId=consumer-my-group-3, groupId=my-group] (Re-)joining group
2024-12-07 22:12:26,794 INFO o.a.k.c.c.i.AbstractCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-my-group-2, groupId=my-group] (Re-)joining group
2024-12-07 22:12:26,798 INFO o.a.k.c.c.i.AbstractCoordinator$JoinGroupResponseHandler [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-my-group-2, groupId=my-group] Successfully joined group with generation Generation{generationId=102, memberId='consumer-my-group-2-9e7e5095-7a8c-492e-822d-d7ef9b8567be', protocol='range'}
2024-12-07 22:12:26,798 INFO o.a.k.c.c.i.AbstractCoordinator$JoinGroupResponseHandler [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [Consumer clientId=consumer-my-group-3, groupId=my-group] Successfully joined group with generation Generation{generationId=102, memberId='consumer-my-group-3-e57c731e-4b41-48a7-8e5f-70cb8fec3522', protocol='range'}
2024-12-07 22:12:26,801 INFO o.a.k.c.u.AppInfoParser [Thread-1] App info kafka.consumer for consumer-null-1 unregistered
2024-12-07 22:12:26,802 INFO o.a.b.s.i.k.KafkaUnboundedSource [Thread-1] Partitions assigned to split 0 (total 1): personTopic-0
2024-12-07 22:12:26,827 INFO o.a.k.c.c.i.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-my-group-2, groupId=my-group] Finished assignment for group at generation 102: {consumer-my-group-3-e57c731e-4b41-48a7-8e5f-70cb8fec3522=Assignment(partitions=[oddTopic-0]), consumer-my-group-2-9e7e5095-7a8c-492e-822d-d7ef9b8567be=Assignment(partitions=[evenTopic-0])}
2024-12-07 22:12:26,850 INFO o.a.k.c.c.i.AbstractCoordinator$SyncGroupResponseHandler [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-my-group-2, groupId=my-group] Successfully synced group in generation Generation{generationId=102, memberId='consumer-my-group-2-9e7e5095-7a8c-492e-822d-d7ef9b8567be', protocol='range'}
2024-12-07 22:12:26,850 INFO o.a.k.c.c.i.AbstractCoordinator$SyncGroupResponseHandler [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [Consumer clientId=consumer-my-group-3, groupId=my-group] Successfully synced group in generation Generation{generationId=102, memberId='consumer-my-group-3-e57c731e-4b41-48a7-8e5f-70cb8fec3522', protocol='range'}
2024-12-07 22:12:26,857 INFO o.a.k.c.c.i.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [Consumer clientId=consumer-my-group-3, groupId=my-group] Notifying assignor about the new Assignment(partitions=[oddTopic-0])
2024-12-07 22:12:26,860 INFO o.a.k.c.c.i.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-my-group-2, groupId=my-group] Notifying assignor about the new Assignment(partitions=[evenTopic-0])
2024-12-07 22:12:26,863 INFO o.a.k.c.c.i.ConsumerRebalanceListenerInvoker [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [Consumer clientId=consumer-my-group-3, groupId=my-group] Adding newly assigned partitions: oddTopic-0
2024-12-07 22:12:26,864 INFO o.a.k.c.c.i.ConsumerRebalanceListenerInvoker [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-my-group-2, groupId=my-group] Adding newly assigned partitions: evenTopic-0
2024-12-07 22:12:26,889 INFO o.a.k.c.c.i.ConsumerUtils [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] Setting offset for partition evenTopic-0 to the committed offset FetchPosition{offset=68, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 0 rack: null)], epoch=0}}
2024-12-07 22:12:26,889 INFO o.a.k.c.c.i.ConsumerUtils [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] Setting offset for partition oddTopic-0 to the committed offset FetchPosition{offset=36, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 0 rack: null)], epoch=0}}
2024-12-07 22:12:26,901 INFO o.s.c.l.LogAccessor [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] my-group: partitions assigned: [oddTopic-0]
2024-12-07 22:12:26,901 INFO o.s.c.l.LogAccessor [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] my-group: partitions assigned: [evenTopic-0]
2024-12-07 22:12:26,927 INFO o.a.k.c.c.AbstractConfig [direct-runner-worker] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-null-4
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = null
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 524288
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2024-12-07 22:12:26,937 INFO o.a.k.c.t.i.KafkaMetricsCollector$StateLedger [direct-runner-worker] initializing Kafka metrics collector
2024-12-07 22:12:26,979 INFO o.a.k.c.u.AppInfoParser$AppInfo [direct-runner-worker] Kafka version: 3.8.1
2024-12-07 22:12:26,979 INFO o.a.k.c.u.AppInfoParser$AppInfo [direct-runner-worker] Kafka commitId: 70d6ff42debf7e17
2024-12-07 22:12:26,979 INFO o.a.k.c.u.AppInfoParser$AppInfo [direct-runner-worker] Kafka startTimeMs: 1733589746978
2024-12-07 22:12:27,011 INFO o.a.k.c.c.i.LegacyKafkaConsumer [direct-runner-worker] [Consumer clientId=consumer-null-4, groupId=null] Assigned to partition(s): personTopic-0
2024-12-07 22:12:27,034 INFO o.a.k.c.Metadata [KafkaConsumerPoll-thread] [Consumer clientId=consumer-null-4, groupId=null] Cluster ID: gI2WBDqdQ9Kcc-CZ22MWVA
2024-12-07 22:12:27,043 INFO o.a.k.c.c.i.SubscriptionState [KafkaConsumerPoll-thread] [Consumer clientId=consumer-null-4, groupId=null] Resetting offset for partition personTopic-0 to position FetchPosition{offset=83, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 0 rack: null)], epoch=0}}.
2024-12-07 22:12:27,046 INFO o.a.b.s.i.k.KafkaUnboundedReader [direct-runner-worker] Reader-0: reading from personTopic-0 starting at offset 83
2024-12-07 22:12:27,050 INFO o.a.k.c.c.AbstractConfig [direct-runner-worker] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-Reader-0_offset_consumer_618237815_none-5
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = Reader-0_offset_consumer_618237815_none
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 524288
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2024-12-07 22:12:27,052 INFO o.a.k.c.t.i.KafkaMetricsCollector$StateLedger [direct-runner-worker] initializing Kafka metrics collector
2024-12-07 22:12:27,070 INFO o.a.k.c.u.AppInfoParser$AppInfo [direct-runner-worker] Kafka version: 3.8.1
2024-12-07 22:12:27,070 INFO o.a.k.c.u.AppInfoParser$AppInfo [direct-runner-worker] Kafka commitId: 70d6ff42debf7e17
2024-12-07 22:12:27,070 INFO o.a.k.c.u.AppInfoParser$AppInfo [direct-runner-worker] Kafka startTimeMs: 1733589747070
2024-12-07 22:12:27,091 INFO o.a.k.c.Metadata [direct-runner-worker] [Consumer clientId=consumer-Reader-0_offset_consumer_618237815_none-5, groupId=Reader-0_offset_consumer_618237815_none] Cluster ID: gI2WBDqdQ9Kcc-CZ22MWVA
2024-12-07 22:13:18,423 INFO o.a.k.c.c.i.ConsumerRebalanceListenerInvoker [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [Consumer clientId=consumer-my-group-3, groupId=my-group] Revoke previously assigned partitions oddTopic-0
2024-12-07 22:13:18,423 INFO o.a.k.c.c.i.ConsumerRebalanceListenerInvoker [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-my-group-2, groupId=my-group] Revoke previously assigned partitions evenTopic-0
2024-12-07 22:13:18,464 INFO o.s.c.l.LogAccessor [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] my-group: partitions revoked: [evenTopic-0]
2024-12-07 22:13:18,464 INFO o.s.c.l.LogAccessor [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] my-group: partitions revoked: [oddTopic-0]
2024-12-07 22:13:18,471 INFO o.a.k.c.c.i.AbstractCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [Consumer clientId=consumer-my-group-3, groupId=my-group] Member consumer-my-group-3-e57c731e-4b41-48a7-8e5f-70cb8fec3522 sending LeaveGroup request to coordinator localhost:9092 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
2024-12-07 22:13:18,471 INFO o.a.k.c.c.i.AbstractCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-my-group-2, groupId=my-group] Member consumer-my-group-2-9e7e5095-7a8c-492e-822d-d7ef9b8567be sending LeaveGroup request to coordinator localhost:9092 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
2024-12-07 22:13:18,474 INFO o.a.k.c.c.i.AbstractCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-my-group-2, groupId=my-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2024-12-07 22:13:18,474 INFO o.a.k.c.c.i.AbstractCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [Consumer clientId=consumer-my-group-3, groupId=my-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2024-12-07 22:13:18,474 INFO o.a.k.c.c.i.AbstractCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-my-group-2, groupId=my-group] Request joining group due to: consumer pro-actively leaving the group
2024-12-07 22:13:18,475 INFO o.a.k.c.c.i.AbstractCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [Consumer clientId=consumer-my-group-3, groupId=my-group] Request joining group due to: consumer pro-actively leaving the group
2024-12-07 22:13:18,475 INFO o.a.k.c.c.i.LegacyKafkaConsumer [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [Consumer clientId=consumer-my-group-3, groupId=my-group] Unsubscribed all topics or patterns and assigned partitions
2024-12-07 22:13:18,475 INFO o.a.k.c.c.i.LegacyKafkaConsumer [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-my-group-2, groupId=my-group] Unsubscribed all topics or patterns and assigned partitions
2024-12-07 22:13:18,481 INFO o.a.k.c.c.i.AbstractCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-my-group-2, groupId=my-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2024-12-07 22:13:18,481 INFO o.a.k.c.c.i.AbstractCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [Consumer clientId=consumer-my-group-3, groupId=my-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2024-12-07 22:13:18,483 INFO o.a.k.c.c.i.AbstractCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [Consumer clientId=consumer-my-group-3, groupId=my-group] Request joining group due to: consumer pro-actively leaving the group
2024-12-07 22:13:18,484 INFO o.a.k.c.c.i.AbstractCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-my-group-2, groupId=my-group] Request joining group due to: consumer pro-actively leaving the group
2024-12-07 22:13:18,701 INFO o.a.k.c.m.Metrics [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] Metrics scheduler closed
2024-12-07 22:13:18,701 INFO o.a.k.c.m.Metrics [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] Metrics scheduler closed
2024-12-07 22:13:18,705 INFO o.a.k.c.m.Metrics [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2024-12-07 22:13:18,705 INFO o.a.k.c.m.Metrics [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2024-12-07 22:13:18,705 INFO o.a.k.c.m.Metrics [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2024-12-07 22:13:18,705 INFO o.a.k.c.m.Metrics [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2024-12-07 22:13:18,707 INFO o.a.k.c.m.Metrics [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] Metrics reporters closed
2024-12-07 22:13:18,707 INFO o.a.k.c.m.Metrics [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] Metrics reporters closed
2024-12-07 22:13:18,722 INFO o.a.k.c.u.AppInfoParser [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] App info kafka.consumer for consumer-my-group-2 unregistered
2024-12-07 22:13:18,726 INFO o.a.k.c.u.AppInfoParser [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] App info kafka.consumer for consumer-my-group-3 unregistered
2024-12-07 22:13:18,728 INFO o.s.c.l.LogAccessor [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] my-group: Consumer stopped
2024-12-07 22:13:18,727 INFO o.s.c.l.LogAccessor [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] my-group: Consumer stopped
2024-12-07 22:13:18,745 INFO o.s.b.w.e.t.GracefulShutdown [SpringApplicationShutdownHook] Commencing graceful shutdown. Waiting for active requests to complete
2024-12-07 22:13:18,770 INFO o.s.b.w.e.t.GracefulShutdown [tomcat-shutdown] Graceful shutdown complete
2024-12-07 22:13:26,628 ERROR o.s.b.SpringApplication [main] Application run failed
java.lang.IllegalStateException: java.lang.IllegalStateException: Logback configuration error detected: 
ERROR in ch.qos.logback.core.model.processor.PropertyModelHandler - In <property> element, either the "file" attribute alone, or the "resource" element alone, or both the "name" and "value" attributes must be set.
	at org.springframework.boot.context.logging.LoggingApplicationListener.initializeSystem(LoggingApplicationListener.java:347)
	at org.springframework.boot.context.logging.LoggingApplicationListener.initialize(LoggingApplicationListener.java:298)
	at org.springframework.boot.context.logging.LoggingApplicationListener.onApplicationEnvironmentPreparedEvent(LoggingApplicationListener.java:246)
	at org.springframework.boot.context.logging.LoggingApplicationListener.onApplicationEvent(LoggingApplicationListener.java:223)
	at org.springframework.context.event.SimpleApplicationEventMulticaster.doInvokeListener(SimpleApplicationEventMulticaster.java:185)
	at org.springframework.context.event.SimpleApplicationEventMulticaster.invokeListener(SimpleApplicationEventMulticaster.java:178)
	at org.springframework.context.event.SimpleApplicationEventMulticaster.multicastEvent(SimpleApplicationEventMulticaster.java:156)
	at org.springframework.context.event.SimpleApplicationEventMulticaster.multicastEvent(SimpleApplicationEventMulticaster.java:138)
	at org.springframework.boot.context.event.EventPublishingRunListener.multicastInitialEvent(EventPublishingRunListener.java:136)
	at org.springframework.boot.context.event.EventPublishingRunListener.environmentPrepared(EventPublishingRunListener.java:81)
	at org.springframework.boot.SpringApplicationRunListeners.lambda$environmentPrepared$2(SpringApplicationRunListeners.java:64)
	at java.base/java.lang.Iterable.forEach(Iterable.java:75)
	at org.springframework.boot.SpringApplicationRunListeners.doWithListeners(SpringApplicationRunListeners.java:118)
	at org.springframework.boot.SpringApplicationRunListeners.doWithListeners(SpringApplicationRunListeners.java:112)
	at org.springframework.boot.SpringApplicationRunListeners.environmentPrepared(SpringApplicationRunListeners.java:63)
	at org.springframework.boot.SpringApplication.prepareEnvironment(SpringApplication.java:353)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:313)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1361)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1350)
	at com.assignment.DemoApplication.main(DemoApplication.java:14)
Caused by: java.lang.IllegalStateException: Logback configuration error detected: 
ERROR in ch.qos.logback.core.model.processor.PropertyModelHandler - In <property> element, either the "file" attribute alone, or the "resource" element alone, or both the "name" and "value" attributes must be set.
	at org.springframework.boot.logging.logback.LogbackLoggingSystem.reportConfigurationErrorsIfNecessary(LogbackLoggingSystem.java:291)
	at org.springframework.boot.logging.logback.LogbackLoggingSystem.loadConfiguration(LogbackLoggingSystem.java:269)
	at org.springframework.boot.logging.logback.LogbackLoggingSystem.reinitialize(LogbackLoggingSystem.java:344)
	at org.springframework.boot.logging.AbstractLoggingSystem.initializeWithConventions(AbstractLoggingSystem.java:74)
	at org.springframework.boot.logging.AbstractLoggingSystem.initialize(AbstractLoggingSystem.java:61)
	at org.springframework.boot.logging.logback.LogbackLoggingSystem.initialize(LogbackLoggingSystem.java:197)
	at org.springframework.boot.context.logging.LoggingApplicationListener.initializeSystem(LoggingApplicationListener.java:332)
	... 19 common frames omitted
2024-12-07 22:15:30,401 ERROR o.s.b.SpringApplication [main] Application run failed
java.lang.IllegalStateException: java.lang.IllegalStateException: Logback configuration error detected: 
ERROR in ch.qos.logback.core.model.processor.PropertyModelHandler - In <property> element, either the "file" attribute alone, or the "resource" element alone, or both the "name" and "value" attributes must be set.
	at org.springframework.boot.context.logging.LoggingApplicationListener.initializeSystem(LoggingApplicationListener.java:347)
	at org.springframework.boot.context.logging.LoggingApplicationListener.initialize(LoggingApplicationListener.java:298)
	at org.springframework.boot.context.logging.LoggingApplicationListener.onApplicationEnvironmentPreparedEvent(LoggingApplicationListener.java:246)
	at org.springframework.boot.context.logging.LoggingApplicationListener.onApplicationEvent(LoggingApplicationListener.java:223)
	at org.springframework.context.event.SimpleApplicationEventMulticaster.doInvokeListener(SimpleApplicationEventMulticaster.java:185)
	at org.springframework.context.event.SimpleApplicationEventMulticaster.invokeListener(SimpleApplicationEventMulticaster.java:178)
	at org.springframework.context.event.SimpleApplicationEventMulticaster.multicastEvent(SimpleApplicationEventMulticaster.java:156)
	at org.springframework.context.event.SimpleApplicationEventMulticaster.multicastEvent(SimpleApplicationEventMulticaster.java:138)
	at org.springframework.boot.context.event.EventPublishingRunListener.multicastInitialEvent(EventPublishingRunListener.java:136)
	at org.springframework.boot.context.event.EventPublishingRunListener.environmentPrepared(EventPublishingRunListener.java:81)
	at org.springframework.boot.SpringApplicationRunListeners.lambda$environmentPrepared$2(SpringApplicationRunListeners.java:64)
	at java.base/java.lang.Iterable.forEach(Iterable.java:75)
	at org.springframework.boot.SpringApplicationRunListeners.doWithListeners(SpringApplicationRunListeners.java:118)
	at org.springframework.boot.SpringApplicationRunListeners.doWithListeners(SpringApplicationRunListeners.java:112)
	at org.springframework.boot.SpringApplicationRunListeners.environmentPrepared(SpringApplicationRunListeners.java:63)
	at org.springframework.boot.SpringApplication.prepareEnvironment(SpringApplication.java:353)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:313)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1361)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1350)
	at com.assignment.DemoApplication.main(DemoApplication.java:14)
Caused by: java.lang.IllegalStateException: Logback configuration error detected: 
ERROR in ch.qos.logback.core.model.processor.PropertyModelHandler - In <property> element, either the "file" attribute alone, or the "resource" element alone, or both the "name" and "value" attributes must be set.
	at org.springframework.boot.logging.logback.LogbackLoggingSystem.reportConfigurationErrorsIfNecessary(LogbackLoggingSystem.java:291)
	at org.springframework.boot.logging.logback.LogbackLoggingSystem.loadConfiguration(LogbackLoggingSystem.java:269)
	at org.springframework.boot.logging.logback.LogbackLoggingSystem.reinitialize(LogbackLoggingSystem.java:344)
	at org.springframework.boot.logging.AbstractLoggingSystem.initializeWithConventions(AbstractLoggingSystem.java:74)
	at org.springframework.boot.logging.AbstractLoggingSystem.initialize(AbstractLoggingSystem.java:61)
	at org.springframework.boot.logging.logback.LogbackLoggingSystem.initialize(LogbackLoggingSystem.java:197)
	at org.springframework.boot.context.logging.LoggingApplicationListener.initializeSystem(LoggingApplicationListener.java:332)
	... 19 common frames omitted
2024-12-07 22:16:16,770 ERROR o.s.b.SpringApplication [main] Application run failed
java.lang.IllegalStateException: java.lang.IllegalStateException: Logback configuration error detected: 
ERROR in ch.qos.logback.core.model.processor.PropertyModelHandler - In <property> element, either the "file" attribute alone, or the "resource" element alone, or both the "name" and "value" attributes must be set.
	at org.springframework.boot.context.logging.LoggingApplicationListener.initializeSystem(LoggingApplicationListener.java:347)
	at org.springframework.boot.context.logging.LoggingApplicationListener.initialize(LoggingApplicationListener.java:298)
	at org.springframework.boot.context.logging.LoggingApplicationListener.onApplicationEnvironmentPreparedEvent(LoggingApplicationListener.java:246)
	at org.springframework.boot.context.logging.LoggingApplicationListener.onApplicationEvent(LoggingApplicationListener.java:223)
	at org.springframework.context.event.SimpleApplicationEventMulticaster.doInvokeListener(SimpleApplicationEventMulticaster.java:185)
	at org.springframework.context.event.SimpleApplicationEventMulticaster.invokeListener(SimpleApplicationEventMulticaster.java:178)
	at org.springframework.context.event.SimpleApplicationEventMulticaster.multicastEvent(SimpleApplicationEventMulticaster.java:156)
	at org.springframework.context.event.SimpleApplicationEventMulticaster.multicastEvent(SimpleApplicationEventMulticaster.java:138)
	at org.springframework.boot.context.event.EventPublishingRunListener.multicastInitialEvent(EventPublishingRunListener.java:136)
	at org.springframework.boot.context.event.EventPublishingRunListener.environmentPrepared(EventPublishingRunListener.java:81)
	at org.springframework.boot.SpringApplicationRunListeners.lambda$environmentPrepared$2(SpringApplicationRunListeners.java:64)
	at java.base/java.lang.Iterable.forEach(Iterable.java:75)
	at org.springframework.boot.SpringApplicationRunListeners.doWithListeners(SpringApplicationRunListeners.java:118)
	at org.springframework.boot.SpringApplicationRunListeners.doWithListeners(SpringApplicationRunListeners.java:112)
	at org.springframework.boot.SpringApplicationRunListeners.environmentPrepared(SpringApplicationRunListeners.java:63)
	at org.springframework.boot.SpringApplication.prepareEnvironment(SpringApplication.java:353)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:313)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1361)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1350)
	at com.assignment.DemoApplication.main(DemoApplication.java:14)
Caused by: java.lang.IllegalStateException: Logback configuration error detected: 
ERROR in ch.qos.logback.core.model.processor.PropertyModelHandler - In <property> element, either the "file" attribute alone, or the "resource" element alone, or both the "name" and "value" attributes must be set.
	at org.springframework.boot.logging.logback.LogbackLoggingSystem.reportConfigurationErrorsIfNecessary(LogbackLoggingSystem.java:291)
	at org.springframework.boot.logging.logback.LogbackLoggingSystem.loadConfiguration(LogbackLoggingSystem.java:269)
	at org.springframework.boot.logging.AbstractLoggingSystem.initializeWithConventions(AbstractLoggingSystem.java:81)
	at org.springframework.boot.logging.AbstractLoggingSystem.initialize(AbstractLoggingSystem.java:61)
	at org.springframework.boot.logging.logback.LogbackLoggingSystem.initialize(LogbackLoggingSystem.java:197)
	at org.springframework.boot.context.logging.LoggingApplicationListener.initializeSystem(LoggingApplicationListener.java:332)
	... 19 common frames omitted
